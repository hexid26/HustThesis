\chapter{面向任务卸载的边缘网络调度机制}

在移动群智感知中，由于移动设备的处理能力存在个体差异，计算能力较弱的移动设备会将部分感知数据处理任务卸载至边缘服务器上，以减少因本地数据处理导致的时延。
当使用软件定义网络(SDN)管理网络资源时，SDN 路由器的流表容量因三进制内容可寻址存储器（Ternary content addressable memory，简称TCAM）的容量而受到不可避免的限制。
% 这里要修改
面对无处不在的移动设备，SDN 在调度移动设备的网络链接时，必须考虑流表容量、带宽和任务卸载之间的约束。
基于这些约束条件，本章构建了 ILP（Integer Linear Programming）模型来理解负载决策、传输延迟和以及感知数据处理成本之间的关系。
然后提出二阶段决策算法，根据 SDN 交换机中的流表容量和链路带宽来调度移动设备和边缘服务器的通信链路，并保障任务卸载所带来的能耗收益。
通过对比评估，验证了算法的可行性。并在 SDN 路由器流表不溢出的情况下，达到最佳调度方案90\%的节能效益。

\section{研究背景}

% 这里要修改
对于移动群智感知而言，大部分研究工作将重心放在志愿者激励~\cite{CNKI:JiaChaopeng, DBLP:journals/comsur/ZhangYSLTXM16, CNKI:WuMCSIncentive}和任务分发工作上~\cite{DBLP:conf/huc/LiuGWWYZ16, DBLP:conf/infocom/Xiao0HWL15, DBLP:conf/mass/LiLW15}，这些工作已经取得了良好的效果。
因此，本章的研究重点围绕感知数据的收集工作展开。
在群智感知数据收集过程中，需要移动设备对感知数据进行一定的处理工作再进行上传。
对于普通的数值读取式传感器，这类传感数据体积小、处理容易，大部分的移动设备可以快速完成原始感知数据的处理工作。
然而，对于视频、音频、图像、雷达信号等类别的传感数据，由于原始感知数据信息量大、且处理算法工作复杂度高，在没有专用芯片帮助下，移动设备无法对这类原始感知数据进行实时处理。
为了解决这类原始感知数据的处理工作，在移动群智感知场景中常依靠计算卸载技术借助外部算力对这些感知数据进行处理。

由于移动设备个体性能的差异，同一计算任务在不同移动设备上的运行时间和能耗开销也存在较大的区别。
对于性能较弱的移动设备而言，为了加快部分应用的执行速度，可以使用计算任务卸载技术~\cite{Lee:2013fj, Linthicum:2017vv, Kumar:2013dq}，将本地难以高效执行的计算过程，迁移到计算能力充沛的云端服务器上，从而提高应用执行效率。
例如，使用移动设备执行导航应用，用户只需要上报自己的地理位置和目的地，路线规划和地图资源则在云端准备完成后再反馈给用户。
通过云存储服务，用户之间可以快速完成数据分享，无需消耗本地设备的存储资源。
利用任务卸载技术，可以帮助性能较弱的终端设备完成复杂任务，降低执行成本。

在移动群智感知的执行过程中，计算任务卸载技术也被广泛应用。
在城市感知中，多使用网络摄像头等设备采集大量的视频、图像、音频数据。
对于这些感知设备，其计算能力并不能满足对原始数据实时处理的需求，也没有足够的存储资源保存原始数据。
因此，对于这一类群智感知应用，需要在靠近感知设备的位置部署相应的数据处理服务和存储资源，对原始感知数据进行实时处理并缓存，才能确保感知应用的执行效率。
针对这一需求，可以利用边缘计算在数据产生源附近的边缘服务器上部署相应的服务，来实现原始感知数据的实时处理。

然而，边缘计算不同于云计算模型，边缘网络中的边缘服务器分布更为独立，没有独立的内部网络支撑计算任务在不同服务器之间的调度。
因此，在进行计算任务卸载时，感知设备和边缘服务器之间的网络链接也需要进行协同调度。
基于这一目的，在边缘网络中使用 SDN 对网络资源进行管理，利用其控制平面和数据平面的隔离的特征~\cite{Committee:2012un}，实现计算任务卸载和网络资源的协同调度。

% 网络中的设备数量和流量类型正在急剧增长。为了更有效地管理网络，新出现的网络架构SDN被发明出来。SDN的目标是分离控制平面和数据平面~\cite{Committee:2012un}。SDN采用可编程网络，并利用虚拟化技术，这与其他网络体系结构不同。同时，SDN还可以共享网络基础设施，使网络功能实现软件化。

\begin{figure}[!h]
  \centering
  \includegraphics[width=440pt]{./figures/Sec_ISPA/OffloadingSDN.pdf}
  \vspace{-1em}
  \caption{基于 SDN 的计算任务卸载和网络资源协同调度}
  \vspace{-1em}
  \label{fig_OffloadingSDN}
\end{figure}

图~\ref{fig_OffloadingSDN} 展示了移动群智感知中，计算任务卸载和网络资源的协同调度场景。
\textbf{『加入描述』}

尽管利用 SDN 可以在边缘网络中实现基于计算任务卸载的网络资源调度，但是在面对成千上万的感知设备时，SDN 能够管理的网络资源会因流表容量受到一定的约束。
在 SDN 交换机中，多路径路由规则通常使用 TCAM 芯片进行存储，而 TCAM 芯片的容量，则代表 SDN 交换机可以存放在流表~\cite{Dasgupta:2012:DMD:2400771.2401550}中的多路径转发规则的数量。
但是由于 TCAM 芯片成本过高，所以 SDN 交换机中的流表通常只能保存10000到15000条转发规则。
所以，在调度计算任务卸载的过程中，不仅要考虑感知设备与边缘服务器的链路带宽、时延是否满足需求，还需要考虑 SDN 路由器能否支撑大量感知设备的多路径转发规则存储。

基于上述种种约束条件，在移动群智感知应用中，网络资源的调度必须考虑网络中链路的带宽、延时、SDN 交换机的流表容量、以及计算任务卸载之间的约束关系。
为此，本文提出一种新的链路调度算法对群智感知中计算任务卸载和边缘网络资源进行协同调度，
以达到网络资源负载均衡、保障计算任务卸载的服务质量、并最大限度地降低感知数据处理能耗。
本章的主要贡献如下：

1）建立 ILP（Integer Linear Programming）模型来描述计算任务卸载决策、网络资源调度、和感知数据处理能耗之间的关系。

2）为解决 ILP 模型求解的高计算复杂性，提出了两阶段网络资源调度算法，并通过模拟实验验证了该算法的正确性和有效性。

\section{问题描述}

为了对真实场景进行抽象描述，本节以图~\ref{fig_scenario} 为原型对本章的研究问题进行描述。
在现实场景中，通常以子基站围绕主基站的方式部署无线通信网络。
在主基站中，为了辅助通信业务和应用，会增加额外的计算资源和存储资源。
因此，主基站可以作为边缘网络中的边缘服务器，作为感知设备计算任务卸载的目的地。
为了提高无线网络的覆盖率，主基站利用子基站或者无线网络接入点（Wireless Access Point，简称 AP）将网络资源覆盖到更广阔的地理空间中。
通过这种部署，感知设备可以直接利用子基站传输数据，也可以通过子基站再经由主基站完成数据的传输工作。
然而收到地理分布的影响，不同基站之间的链接也有延时和带宽的差异。
因此，感知设备在进行计算任务卸载的同时，不仅需要考虑主基站的性能负载，还需要考虑网络资源中带宽和延时的影响。

\begin{figure}[!h]
  % \vspace{-1em}
  \centering
  \includegraphics[width=440pt]{./figures/Sec_ISPA/scenario.pdf}
  \vspace{-1em}
  \caption{基于感知数据计算任务卸载的边缘计算场景}
  \label{fig_scenario}
\end{figure}

根据图~\ref{fig_scenario} 所描述的场景，建立分析模型时需要考虑的对象分为三类：
感知设备，2）由 SDN 支撑的子基站，3）可执行感知数据计算任务的主基站。
为了让模型专注于研究计算任务调度和网络资环的协同调度关系，本章在场景建立时做出以下假设: 

（1）计算任务在感知设备或主基站都是独立运行；

（2）基站之间的通信链路可利用资源是稳定的；

（3）所有网络连接均通过 SDN 管理。


% 如图~\ref{fig_scenario} 所示，每个用户通过固定AP访问网络资源。用户和主基站之间的所有链接都由SDN分配。SDN的主要职责是为所有用户安排链路，以提高他们的QoS。同时，SDN的工作对用户是透明的。为了满足更多用户，可以租用云计算资源，如虚拟专用服务器（VPS）、Docker等。你想要的资源越多，你就需要付出越多。

在该场景中，使用$u$来代表单一的感知设备，使用$\boldsymbol{U}$代表所有感知设备构成的集合（ $ u \in \boldsymbol{U} $）。
在边缘网络中，可以执行计算任务的主基站用$s$表示，$\boldsymbol{S}$ （ $ s \in \boldsymbol{S} $）代表这类基站的集合。
负责数据转发的子基站和 AP，使用$r$表示，并用$\boldsymbol{R}$ （ $ r \in \boldsymbol{R} $）代表这类基站的集合。
考虑到 SDN 通过保存多路径转发规则管理链路，这里使用$l$表示感知设备到主基站的一条链路，$ \boldsymbol{L} ( l \in \boldsymbol{L} ) $代表所有感知设备与所有主基站能够建立的全部链接集合。
由于一个感知设备到一个主基站可能存在多条路径，可以利用$l$是否经过$r$来区分起始、终点相同的路径（在章节~\ref{Constraints} 中描述）。
为了抽象各种设备的计算能力，将计算能力定义为$\mu$，用$\mu_s$表示云主基站$s$的计算能力，用$\mu_u$表示感知设备$u$的本地计算能力。

\begin{figure}[!h]
  \centering
  \vspace{-1em}
  \includegraphics[width=300pt]{./figures/Sec_ISPA/Delay.pdf}
  \vspace{-1em}
  \caption{计算任务卸载时延\textbf{『需要重画』}}
  \vspace{-1em}
  \label{fig_timestaps}
\end{figure}

由于计算任务卸载需要将感知设备将数据交付给主基站，并等待主基站完成任务给予反馈，因此计算任务卸载的发起到完成确认，需要一定的时间开销。
在图~\ref{fig_timestaps} 中，${T}_{us}$是从感知设备$u$到主基站$s$的时延。
$\Tsu$代表从主基站$s$到感知设备$u$的时延。
$\Tuscloud$是感知设备$u$的计算任务在主基站$s$中的执行时间。
$\Tusresponse$是感知设备$u$将计算任务卸载到主基站$s$的总时间开销。
基于之间的假设条件（2），基站之间的通信链路都处于稳定状态。
因此，在感知设备和主基站之间的通信链路不改变的情况下，感知设备和主基站之间的通信延时$\Tus$和$\Tsu$可视为常数。
仅当 SDN 网络在资源调度时改变了感知设备和主基站之间的通信链路，$\Tus$和$\Tsu$才会跟随新的链路发生改变。
在此模型中，主基站的计算响应时间$\Tusresponse$可以通过延时的总和来计算，如式~\eqref{formula_cloudtime} 所示。

% 图~\ref{fig_timestaps} 用于理解每个步骤中的时延。在图中，${T}_{us}$是从用户$u$到服务器$s$的时延。 $\Tsu$是从服务器$s$到用户$u$的延迟。 $\Tuscloud$是用户$u$在服务器$s$中的执行时间。 $\Tusresponse$是将任务从用户$u$卸载到服务器$s$的总时间。鉴于假设条件（2），用户和服务器之间的时间成本是恒定的。 同时，SDN网络没有为用户指定AP，因为用户更喜欢最稳定的网络服务。 由于用户和接入点之间的等待时间可以被视为常数，因此不需要将等待时间分成两部分。 然而，当用户发起任务时，SDN网络可以帮助用户选择不同的链接进行上传和下载。 因此，$\Tus$和$\Tsu$适合用作用户和服务器之间延迟的参数。

% \vspace{-1.5em}
\begin{equation}
\label{formula_cloudtime}
% \begin{aligned}
\Tusresponse = \Tus + \Tsu + \Tuscloud,\ \forall \ u \in \boldsymbol{U}, s \in \boldsymbol{S}
% \end{aligned}
\end{equation}

\section{面向任务卸载的边缘网络调度模型及算法}

为了用数学方法更好地描述这个模型，本节使用了表~\ref{table_notations_ispa} 中定义的数学符号。 这些符号的细节将在后面解释。

\begin{table}[!h]
  \caption{数学符号及定义\textbf{『补完修订』}}
  \vspace{-1em}
  \label{table_notations_ispa}
  \centering
  \begin{tabular}{c|p{8cm}}
  \hline
  \textbf{数学符号} & \textbf{定义}\\
  \hline
  $\boldsymbol{U}$ & 由感知设备 $u$ 构成的集合\\\hline
  $\boldsymbol{S}$ & 由主基站 $s$ 构成的集合\\\hline
  $\boldsymbol{R}$ & 由 SDN 路由$r$ 构成的集合\\\hline
  $\Lus$ & 感知设备$u$ 到主基站 $s$ 的链路 $\lus$ 构成的集合\\\hline
  $\xlus$ & $\lus$ 是否作为感知设备$u$ 到主基站 $s$ 的上行链路\\\hline
  $\ylus$ & $\lus$ 是否作为感知设备$u$ 到主基站 $s$ 的下行链路\\\hline
  $\Tlus$ & 链路$\lus$的传输时延\\\hline
  $\Blus$ & 链路 $\lus$的带宽资源\\\hline
  $\xrl$ & 链路 $\lus$ 是否经过子基站 $r$\\\hline
  $\Bu$ & 感知设备 $u$的上行链路带宽需求\\\hline
  $\Bd$ & 感知设备 $u$的下行链路带宽需求\\\hline
  $\eu$ & 感知设备 $u$ 执行计算任务的能耗开销\\\hline
  $\es$ & 主基站 $s$ 执行计算任务的能耗开销\\\hline
  $\lambdau$ & 感知设备$u$上的计算任务到达率\\\hline
  $\mu_u$ & 感知设备$u$的计算任务处理速度\\\hline
  $\mu_s$ & 主基站$s$的计算任务处理速度\\\hline
  $\xus$ & 感知设备$u$的计算任务是否卸载到主基站$s$\\\hline
  $\aus$ & 感知设备$u$的计算任务卸载到主基站$s$的比例\\\hline
  % $\Tus$ & \\\hline
  % $\Tsu$ & \\\hline
  $T_{QoS}$ & 群智感知应用中计算任务远端执行延时阈值 \\\hline
  \end{tabular}
\end{table}

\subsection{ILP 模型建立}

按照假设条件（1），感知数据的计算任务可以在感知设备或主基站上独立执行。
因此，可以使用二进制变量来指示一个任务是在主基站上执行还是在感知设备中执行。
对于感知设备 $u$，用 $\xus$ 表示计算任务卸载决策。
$\xus = 1$ 时，计算任务在主基站执行，$\xus = 0$ 时，计算任务在本地执行。
另一方面，由于计算任务可以进行划分同时分布在感知设备和主基站上，因此使用 $\aus$（$\aus \in [0,1]$）来代表计算任务的卸载比例。
当 $\aus = 1$ 时，感知设备$u$的计算任务全部在主基站 $s$ 上执行，当 $\aus = 0$ 时，感知设备 $u$ 的计算任务全部在本地执行。

基于上述定义， $\aus$ 和 $\xus$ 之间的关系可以用式~\eqref{formula_xus}来表达。
而 $\xu$ 则可以通过式~\eqref{formula_xu}进行计算。

\begin{equation}
  \label{formula_xus}
  \begin{gathered}
  \frac{\aus}{A} \leq \xus \leq A \cdot \aus \quad (A \to \infty) \\
  \quad \forall \ u \in \boldsymbol{U}, s \in \boldsymbol{S}, \ 0\leq \aus \leq 1
  \end{gathered}
\end{equation}

% \vspace{-0.5em}
\begin{equation}
\label{formula_xu}
\begin{gathered}
\frac{1 - \sum\limits_{s \in \boldsymbol{S}}{\aus}}{A} \leq \xu \leq A \cdot (1 - \sum_{s \in \boldsymbol{S}}{\aus}) \quad (A \to \infty) \\
\forall\ u \in \boldsymbol{U}, s \in \boldsymbol{S}, \ 0\leq \sum_{s \in \boldsymbol{S}}{\aus} \leq 1
\end{gathered}
\end{equation}

根据排队论原理~\cite{Queueing:systems}，在本地执行计算任务的平均时间$T_{u\_local}$，和在主基站中执行计算任务的平均时间$T_{s\_server}$，可以借助 $M/M/1$ 模型计算得出。
$T_{u\_local}$ 和 $T_{s\_server}$ 的计算方法分别如式~\eqref{formula_Tulacal} 和式~\eqref{formula_Tscloud} 所示。
其中，$\lambdau$ 为感知设备 $u$ 上的计算任务平均到达率。

% \vspace{-0.5em}
\begin{equation}
\label{formula_Tulacal}
\Tulocal = \frac{\xu}{\uu - (1 - \sum\limits_{s \in \boldsymbol{S}} \aus) \cdot \lambdau}, \quad \forall \ u \in \boldsymbol{U}
\end{equation}


\begin{equation}
\label{formula_Tscloud}
\Tscloud = \frac{\xus}{\us - \sum\limits_{u \in \boldsymbol{U}} \aus \cdot \lambdau}, \quad \forall \ s \in \boldsymbol{S}
\end{equation}

利用式~\eqref{formula_cloudtime}、式~\eqref{formula_Tulacal} 和式~\eqref{formula_Tscloud}，可以计算感知设备 $u$ 和主基站 $s$ 之间的响应时间 $\Tusresponse$，以预测卸载决策。
而计算任务的卸载决策和通信链路的调度，同时会影响计算任务的处理时延以及感知设备和主基站上的能耗开销。
为了尽可能减小感知设备的能耗和计算任务处理时延，在该模型中提出了相关约束条件。

\subsection{约束条件}
\label{Constraints}

由于感知设备$u$和主基站$s$通信所使用的上行链路和下行链路可能不同，
为了在模型中精确表述感知设备$u$和主基站$s$之间使用的通信链路，
这里使用二进制变量$\xlus$和$\ylus$来表示是否使用$\lus$作为上行链路或下行链路。
由于$\xlus$和$\ylus$的值与计算任务卸载决策$\xus$相关，
因此，$\xlus$、$\ylus$和 $\xus$的值应该满足式~\eqref{formula_xusl1}。


\begin{equation}
\label{formula_xusl}
\begin{aligned}
0 \leq \xlus \leq \xus, \quad \forall \ \lus \in \Lus, u\in \boldsymbol{U}, s\in \boldsymbol{S}\\
0 \leq \ylus \leq \xus, \quad \forall \ \lus \in \Lus, u\in \boldsymbol{U}, s\in \boldsymbol{S}\\
\end{aligned}
\end{equation}

\begin{equation}
\label{formula_xusl1}
\begin{aligned}
&\sum_{\lus \in \Lus}\xlus = 1, \quad \forall \ u\in \boldsymbol{U}, s\in \boldsymbol{S}\\
&\sum_{\lus \in \Lus}\ylus = 1, \quad \forall \ u\in \boldsymbol{U}, s\in \boldsymbol{S}\\
\end{aligned}
\end{equation}

待链路选定后，可以利用$\Tlus$来表示链路$\lus$的延迟。借助$\xlus$和$\ylus$，可以通过式~\eqref{formula_Tus} 计算感知设备$u$和主基站$s$之间上行链路延时$\Tus$和下行链路延时$\Tsu$的数值。

\begin{equation}
\label{formula_Tus}
\begin{aligned}
&\Tus = \xlus \cdot \Tlus, \quad \forall \ \lus \in \Lus, u\in \boldsymbol{U}, s\in \boldsymbol{S}\\
&\Tsu = \ylus \cdot \Tlus, \quad \forall \ \lus \in \Lus, u\in \boldsymbol{U}, s\in \boldsymbol{S}\\
\end{aligned}
\end{equation}

\textbf{计算卸载服务质量约束:}
当感知设备发起计算卸载请求时，该过程可以理解为感知设备根据任务卸载比例将感知数据发送至主基站，主基站反馈任务完成信号。
对于感知设备而言，使用计算卸载的目的就是加速感知数据的处理以调高群智感知的效率。
由于群质感知的生命周期有限，计算任务在调度决策的时候，要尽可能减少计算任务在主基站上的执行时间。
所以计算任务的平均执行时间成为计算任务调度决策的重要参考指标。
在该模型中，可以利用式~\eqref{formula_Tusresponse} 精确获得感知设备$u$的计算任务在主基站$s$上的平均执行时间 $\Tusresponse$。

% 尽管任务可以在本地或云中执行，但是用户总是希望他们能够尽快得到反馈，对于任务在哪里执行，用户并不关心。所以，任务在调度时应尽可能让用户的等待时间减少。因此，平均服务时间是一个非常重要的服务质量指标。通过以上工作，可以利用式~\eqref{formula_Tusresponse} 精确地计算平均服务时间。

\begin{equation}
\label{formula_Tusresponse}
\begin{gathered}
\Tusresponse = \xlus \Tlus + \frac{\xus}{\us-\sum\limits_{u \in \boldsymbol{U}}\aus \cdot \lambdau} + \ylus \Tlus\\
\forall \lus \in \Lus, u\in \boldsymbol{U}, s\in \boldsymbol{S}\\
\end{gathered}
\end{equation}

由于主基站之间可能存在性能差异，在此将计算任务被分配给执行时间最短的主基站。
因此，感知设备$u$的计算任务平均执行时间必须满足式~\eqref{formula_tscloudconstr} 所示的限制条件。
式中，$T_{QoS}$为群智感知应用中感知数据处理延时阈值。

\begin{equation}
\label{formula_tscloudconstr}
\begin{gathered}
% \frac{\xu}{\uu - (1 - \sum\limits_{s \in \boldsymbol{S}} \aus) \cdot \lambdau} \leq T_{QoS},\\
\xlus \Tlus + \frac{\xus}{\us-\sum\limits_{u \in \boldsymbol{U}}\aus \cdot \lambdau} + \ylus \Tlus \leq T_{QoS}\\
\us-\sum\limits_{u \in \boldsymbol{U}}\aus \cdot \lambdau \leq 0\\
\forall \lus \in \Lus, u\in \boldsymbol{U}, s \in \boldsymbol{S}\\
\end{gathered}
\end{equation}

另一方面，任务在感知设备本地执行的响应时间应满足式~\eqref{formula_tulocalconstr} 所示的限制条件。

\begin{equation}
\label{formula_tulocalconstr}
\begin{gathered}
\frac{\xu}{\uu - (1 - \sum\limits_{s \in \boldsymbol{S}} \aus) \cdot \lambdau} \leq T_{QoS}\\
\uu - (1 - \sum\limits_{s \in \boldsymbol{S}}\aus) \cdot \lambdau > 0\\
% \xlus \Tl + \frac{\xus}{\us-\sum\limits_{u \in \boldsymbol{U}}\aus \cdot \lambdau} + \ylus \Tl\\
\forall \ u\in \boldsymbol{U}, s\in \boldsymbol{S}\\
\end{gathered}
\end{equation}

\textbf{带宽资源约束:}
与传统网络一样，SDN中的每条链路都有自己的最大带宽限制。
假设感知设备$u$通过链路$\lus$与主基站$s$连接。
由于感知设备数据众多，中间链路存在严重的复用现象。
因此，链路$\lus$的带宽必须满足所有感知设备的通信需求。
假设链路$\lus$的最大带宽是$\Blus$，并且上行链路和下行链路的带宽需求分别为$\Bu$和$\Bd$。那么约束条件可以描述为式~\eqref{formula_Bandwidth}。

\begin{equation}
\label{formula_Bandwidth}
\begin{gathered}
\sum\limits_{u \in \boldsymbol{U}} \sum\limits_{s\in \boldsymbol{S}}\lambdau\aus(\xlus \cdot \Bu + \ylus \cdot \Bd) \leq \Blus\\
\forall \lus\in \Lus, u\in \boldsymbol{U}, s\in \boldsymbol{S}\\
\end{gathered}
\end{equation}

\textbf{流表容量限制:}
除了带宽限制之外，SDN中的交换机的流表容量也存在上限，即每台 SDN 交换机所能支撑的链路数量存在极限。
在此，利用$r$来表示SDN交换机，$R (r \in R)$表示SDN交换机的集合，并使用$C_r$表示交换机$r$的流表容量。
由于 SDN 交换机存储的是多路径转发规则，这里用二进制变量$\xrl$表示链路$\lus$是否通过交换机$r$，其定义如式~\eqref{formula_xrl} 所示。

\begin{equation}
\label{formula_xrl}
\begin{gathered}
\begin{aligned}
\xrl = \left\{\begin{aligned}
& 0,\quad  \lus \text{ 不经过 SDN 路由器 }\, r\\
& 1,\quad  \lus \text{ 经过 SDN 路由器 }\, r\\
\end{aligned}
\right.
\end{aligned}
\\\forall \ u \in \boldsymbol{U}, s \in \boldsymbol{S}, \lus \in \Lus\\
\end{gathered}
\end{equation}

基于上述定义， SDN 交换机中流表容量的约束条件可以利用$\xrl$来计算，其表达式如式~\eqref{formula_linkconstr}。

\begin{equation}
\label{formula_linkconstr}
\begin{gathered}
\sum\limits_{u \in \boldsymbol{U}}\sum\limits_{s \in \boldsymbol{S}}\sum\limits_{\lus \in Lus}(\xlus + \ylus) \cdot \xrl \leq C_r\\
\forall\ u \in \boldsymbol{U}, s \in \boldsymbol{S}, \lus \in \Lus, r\in R\\
\end{gathered}
\end{equation}

\subsection{优化目标}
如前文所述，建立该 ILP 模型的目标是最小化感知设备的能耗成本。
在此，将感知设备本地执行计算任务的能耗成本定义为$\eu$，将主基站中执行计算任务的能耗成本定义为$\es$。
由于计算任务可以根据计算任务卸载比例$\aus$同时在本地或远程执行。总能源成本$E$可通过式~\eqref{formula_Energy} 计算。

\begin{equation}
\label{formula_Energy}
\begin{gathered}
E = \sum\limits_{u\in \boldsymbol{U}}(\lambdau(1-\sum\limits_{s\in \boldsymbol{S}}\aus)\eu + \lambdau\sum\limits_{s\in \boldsymbol{S}}\aus\es)\\
\forall\ u \in \boldsymbol{U}, s \in \boldsymbol{S}\\
\end{gathered}
\end{equation}

整理上述讨论中的所有约束条件，可以将感知设备的能耗成本转化为『最大-最小』公平问题，其描述如式~\eqref{formula_energy} 所示。

\begin{equation}
\label{formula_energy}
\begin{aligned}
\text{取最小值\:}&{:}\ E\\
% \text{限制条件\:}&{:}\ \text{(6)-(7), (10)-(12), (14)}\\
\text{限制条件\:}&{:}\ 式~\eqref{formula_xusl}, 式~\eqref{formula_xusl1}, 式~\eqref{formula_tscloudconstr},\\
&\ \ 式~\eqref{formula_tulocalconstr}, 式~\eqref{formula_Bandwidth}, 式~\eqref{formula_linkconstr}
\end{aligned}
\end{equation}

\subsection{二阶段网络资源调度算法}

针对本章提出的 ILP 模型，可以利用数学工具计算出计算任务卸载与网络资源调度协同调度的最佳决策。
但是 ILP 模型求解的高计算复杂度，让最佳决策的求解时间大大增加。
同时，随着网络规模的扩大，求解时间也成指数级趋势上升。
为此，本节提出一种二阶段网络资源调度算法，优化求解过程，寻找协同调度的次优调度方法。

该算法主要负责两个阶段的工作。首先，该算法确定$\sum_{s \in \boldsymbol{S}}\aus$和$\sum_{u \in \boldsymbol{U}}\aus$，创建针对感知设备$u$和主基站$s$的不同组合，每种组合创建首选链接集合。
然后，该算法为针对模型中的约束条件，为感知设备$u$和服务器$s$分配最合适的链路，并调整$\aus$，减少感知设备的能源开销。

\begin{algorithm}[!b]
\setstretch{\algostretch}
\KwIn{$\lambdau$ : 感知设备$u$的计算任务到达速率}
\KwIn{$\uu$ : 感知设备$u$的计算任务处理速度}
\KwIn{$\us$: 主基站$s$的计算任务处理速度}
\KwIn{$\eu$: 感知设备执行计算任务的能耗成本}
\KwIn{$\es$ : 主基站执行计算任务的能耗成本}
\KwData{网络结构、每条链路的带宽、延时数据}
% \KwData{$Occ[1:T]$: 每个程序当前的NCP大小，初始为0，随着缓存路的分配增加，最终为每个程序在整个缓存上的NCP}
\If {$\eu \leq \es$}{
  \For{$u \in \boldsymbol{U}$}{
    $\sum_{s \in \boldsymbol{S}}\aus = max(0, 1 - \frac{\uu}{\lambdau})$
  }
}\Else{
  \For{$s \in \boldsymbol{S}$}{
    $\sum_{u \in \boldsymbol{U}}\aus = min(1, \frac{\us}{\lambdau})$
  }
}
\For{$u \in \boldsymbol{U}$}{
  \For{$s \in \boldsymbol{S}$}{
    为感知设备$u$ 和主基站 $s$ 创建可用链路集合$\Lus$\\
    对链路集合$\Lus$ 中的 链路按延时升序排序
  }
}
$\as = \sum_{s \in \boldsymbol{S}}\aus, \  \au = \sum_{u \in \boldsymbol{U}}\aus$\\
\KwOut{$\aus, \au, \Lus$}
\caption{创建感知设备$u$ 和主基站 $s$ 的可选链路集，并根据计算任务的平均执行延时约束决定卸载比例 $\aus$}
\label{algo_aus}
\end{algorithm}

\textbf{第一阶段 （算法~\ref{algo_aus}）}:
在式~\eqref{formula_Energy}，$\lambdau$、$\es$ 和 $\eu$ 是常数。
变量 $\aus$ 是确定感知设备总能耗 $E$ 值的唯一变量。
为了降低总能耗开销，必须在 $\es$ 和 $\eu$ 之间调整系数。
因此，当 $\es > \eu$ 时，$\aus$ 应当使 $\sum_{s \in \boldsymbol{S}}{\aus}$ 取最大值，当 $\es \leq \eu$ 时，$\aus$ 应当使 $\sum_{s \in \boldsymbol{S}}{\aus}$ 取最小值。
因此，该算法第一阶段的工作是找出$\sum_{s \in \boldsymbol{S}}\aus$的取值范围。

利用约束条件~\eqref{formula_tscloudconstr} 和~\eqref{formula_tulocalconstr}，可以得到$\sum_{s \in \boldsymbol{S}}\aus$的范围和$\sum_{u \in \boldsymbol{U}}\aus$的范围：

\vspace{-1em}

\begin{equation*}
\begin{gathered}
\sum_{s \in \boldsymbol{S}}\aus \in [max(0, 1- \frac{\uu}{\lambdau}), 1], \quad \forall\ u \in \boldsymbol{U}, s \in \boldsymbol{S}\\
\sum_{u \in \boldsymbol{U}}\aus \in [0, \frac{\us}{\lambdau}], \quad \forall\ u \in \boldsymbol{U}, s \in \boldsymbol{S}
% \vspace{-1em}
\end{gathered}
\end{equation*}

在确定$\sum_{s \in \boldsymbol{S}}\aus$和$\sum_{u \in \boldsymbol{U}}\aus$的范围后，可以根据约束条件式~\eqref{formula_tulocalconstr} 找出一组从感知设备$u$到主基站$s$的链接集合。
这些信息能够作为算法2的输入，帮助感知设备$u$选择连接主基站$s$的最佳链路。



\textbf{第二阶段 （算法~\ref{algo_findminpaths}）}:
在算法1中，可以得到$\sum_{s \in \boldsymbol{S}}\aus$的最优解。
在此阶段中，本算法负责找出所有$\aus$，使得感知设备$u$ 对不同主基站$s$的卸载比例总和逼近最佳值。
同时，由于流表容量、带宽以及延迟的限制，利用贪心算法和动态规划算法相结合来达到目标。

\begin{algorithm}[h]
\setstretch{\algostretch}
\KwIn{$\as$ : 算法1的输出}
\KwIn{$\au$ : 算法1的输出}
\KwIn{$\Lus$: 算法1的输出}
\KwIn{$T_{QoS}$: 群智感知应用对感知数据处理时延要求的阈值}
\KwData{ SDN 路由器集合$R$以及每个路由器$r$的流表容量 $C_r$}
% \KwData{$Occ[1:T]$: 每个程序当前的NCP大小，初始为0，随着缓存路的分配增加，最终为每个程序在整个缓存上的NCP}
all weights initialized as $0$
all $\aus$ initialized as $0$
$U$ in ascending order of $\lambdau$
$S$ in ascending order of $\us$
\For{$u \in \boldsymbol{U}$}{
  \If {$T_{u\_local} < T_{Qos}$}{
    $\aus = 0, s \in \boldsymbol{S}$
  }
  \Else{
    \For {$s \in \boldsymbol{S}$}{
      \If {$1 \leq \frac{\lambdau}{\us}$ \textbf{and} $T_{s\_cloud} < T_{QoS}$}{
        \For {$l \in \Lus$}{
          \If{$l.weight$ is not exceed $10\%$}{
            $\aus = 1$\\
            $\xlus[u,s,l] = \ylus[u,s,l] =  1$\\
            \textbf{next} $u$
          }
        }
      }
      \If {$T_{s\_cloud} < T_{QoS}$ \textbf{and} $\au < 1$}{
        \For {$l \in \Lus$}{
          \If{$l.weight$ is not exceed $10\%$}{
            $\aus = \frac{\lambdau}{\us}$\\
            $\xlus[u,s,l] = \ylus[u,s,l] =  1$
          }
        }
      }
    }
  }
}
\KwOut{$\xlus$}
\caption{Choose the appropriate link for user $u \in \boldsymbol{U}$}
\label{algo_findminpaths}
\end{algorithm}

首先，按$\lambdau$的升序对感知设备进行排序，再按$\us$升序对主基站进行排序。 这里的策略是优先从计算任务到达速度较慢的感知设备上卸载任务。
一般来说，主基站的能耗成本和其计算性能是正相关的。
因此，主基站的最佳选择策略是在满足平均计算时延的前提条件下，优先使用能耗最小的主基站。
然后，根据第一阶段得出的链接结合$\Lus$，遵循贪心算法来选择感知设备$u$和主基站$s$之间最快的链接。 
由于带宽资源也存在约束条件，所以最快的链路不一定是最佳选择。
因此，再利用动态规划的思量来平衡边缘网络中各链路的带宽占用。
在这一步中，使用流表容量的使用率和链路带宽占用率作为链路选择的权值。

为了保障链路资源的负载均衡，需要避免高质量链路被提前消耗完的窘境。
一旦高质量的链路被占用完全，受影响的感知设备必须降低计算任务卸载比率，这将导致感知设备的能耗成本增加。
因此算法中规定所有链路的两种占用率中，最大值和最小值相差不得超过10\%。
当某个链路的权值比其他链接的权值高出 10\%时，该链接会从可选择链接中屏蔽。
这种设定可以使各链路的带宽负载以及 SDN 路由器中流表的使用率均匀增加，实现链路调度的负载均衡。



% 链路调度算法旨在使带宽使用率和链路使用率同时增长。 在规则空间和带宽限制下保障用户的QoS而不产生额外开销是链路选择的重要依据。 因此，本文的链路调度策略为每个链路设定权重，并且使链路的权重尽可能相近。 所以，两种资源的占用率的权重比例相同。 其中，所有链路的最大权重差值不能超过10\%。 当某个链接的权重比其他链接的权重高出 10\%时，该链接会从可选择链接中屏蔽。 这个策略是为了防止高 QoS 链接被快速占满。 一旦高质量的链路和服务器被占用完全，其余用户必须降低卸载比率以确保QoS，这将导致能耗成本的增加。

\section{实验结果与分析}

为了评估依据权重的链路调度（link scheduling with weight，简称LSW）算法的性能，本节将 LSW 调度算法和最短路径优先（shortest path first，简称 SPF）算法以及利用 Gurobi~\footnote{https://www.gurobi.com} 求得的最优解调度进行比较。
在实验中，使用了两种不同的网络拓扑结构。
第一种是小型网络拓扑，用于验证 LSW 调度算法的可行性。
第二个网络拓扑是一个有拥有100个SDN交换机的模拟网络，用来对比传统的SPF调度算法和LSW调度算法。

\subsection{算法准确性测试}

第一个小型网络的拓扑结构如图~\ref{fig_smallNetwork} 所示。在此图中，定义了每条链路的延迟和带宽。SDN交换机的流表容量依次定义为100，100，80，80，80，100，100。
在该网络中，交换机$0$和交换机$1$是接入点，交换机$5$和交换机$6$连接到不同的主基站。
连接到交换机$6$的主基站比连接到交换机$5$的主基站快10\%。
分布在交换机$0$和交换机$1$之间的感知设备数量从10开始，以10为步进增加至100，且每个感知设备的任务到达率设置为25个任务/秒至50个任务/秒，且均匀分布。
其中，感知设备执行计算任务的能耗成本 $\eu=10$，主基站执行计算任务的能耗成本$\es=100$。

\begin{figure}[!h]
  \centering
  \begin{subfigure}[b]{0.45\linewidth}
    \includegraphics[width=180pt]{./figures/Sec_ISPA/NetworkX_spring_L}
    \label{fig_smallNetworkL}
    \caption{链路延时（秒）}
  \end{subfigure} %
  \begin{subfigure}[b]{0.45\linewidth}    
    \includegraphics[width=180pt]{./figures/Sec_ISPA/NetworkX_spring_B}
    \label{fig_smallNetworkB}
    \caption{链路带宽（兆字节/秒）}
  \end{subfigure} 
  \caption{用于准确性测试的小型网络拓扑}
  \label{fig_smallNetwork}
\end{figure}

利用三种不同的调度方法，首先比较感知设备总能耗的开销。
结果如图~\ref{fig_smallE} 所示，当感知设备数量较少时，由于各类资源占用没有达到阈值，所以链路调度算法不会对感知设备的总能耗产生太大的影响。
随着感知设备数量的增加，其能源成本之间的差距急剧扩大。
当网络中有100个感知设备时，最坏情况下，LSW调度算法产生的感知设备总能耗比最优解（Gurobi计算得出）高12.6 \%；最好情况下，LSW调度算法比SPF调度算法节约26.4\%的感知设备总能耗。
另外，当感知设备达到100时，由于SDN 路由器中的流表容量已经趋于满载，此时可以发现 LSW 调度算法在这种情况情况下存在一定的局限性，导致感知设备总能耗急剧上升。
整体而言，LSW 调度算法所能达到的效果和最优解基本持平，总能耗差异在15\%以内。

\begin{figure}[!t]
  \centering
  \includegraphics[width=290pt]{./figures/Sec_ISPA/small_E}
  \vspace{-1em}
  \caption{不同调度方法对感知设备总能耗的影响}
  % \vspace{-0.5em}
  \label{fig_smallE}
\end{figure}

% 链路调度算法LSW的目标是最小化总能耗$E$。因此，比较了三种方法计算出的不同的$E$值。如图~\ref{fig_smallE} 所示，不同的链路调度策略会影响卸载场景中的总能耗。当用户数量较少时，链路调度算法不会对能耗产生太大影响。随着用户数量的增加，能源成本之间的差距急剧扩大。当网络中有100个用户时，LSW方法的总能耗比最优解（Gurobi计算得出）高12.6 \%，比SPF方法的最优解高36.4\%。同时，100名用户使SDN网络基本上处于满负荷状态。因此，当SDN网络的负载接近满负荷时，LSW方法此时存在局限性。从这个图中，当SDN网络负载不满时，LSW方法和最优解之间的差异可以减少到小于10\%。

\begin{figure}[!h]
  \centering
  \includegraphics[width=290pt]{./figures/Sec_ISPA/small_Au}
  \vspace{-0.5em}
  \caption{不同调度方法对平均计算任务卸载比率的影响}
  \vspace{-0.5em}
  \label{fig_smallAu}
\end{figure}

\begin{figure}[!h]
  \centering
  \begin{subfigure}[h]{0.99\linewidth}
    \centering
    \includegraphics[width=415pt]{./figures/Sec_ISPA/small_rule_grb.pdf}
    \label{fig_smallNetworkRG}
    \vspace{-0.5em}
    \caption{使用 Gurobi 最优解时流表使用率}
  \end{subfigure}
  % \vspace{1em}
  \begin{subfigure}[h]{0.99\linewidth}
    \centering
    \includegraphics[width=415pt]{./figures/Sec_ISPA/small_rule_lsw.pdf}
    \label{fig_smallNetworkRL}
    \vspace{-0.5em}
    \caption{LSW 调度算法下的流表使用率}
  \end{subfigure}
  \begin{subfigure}[h]{0.99\linewidth}
    \centering
    \includegraphics[width=415pt]{./figures/Sec_ISPA/small_rule_spf.pdf}
    \label{fig_smallNetworkRS}
    \vspace{-0.5em}
    \caption{SPF 调度算法下的流表使用率}
  \end{subfigure}
  \vspace{-0.5em}
  \caption{不同调度算法对流表使用率的影响}
% \vspace{-1.2em}
\label{fig_smallrule}
\end{figure}
% \vspace{-1em}

图~\ref{fig_smallAu} 描述的是同一网络拓扑下，不同调度方法对感知设备平均计算任务卸载比率的影响。
图中，感知设备数量从20到50区间，由于感知设备任务到达率以及计算任务处理速度设置的差异，产生了计算任务平均卸载比率上扬的趋势。
但就整体而言，随着感知设备的增加，需要使用的网络资源逐渐增多，当网络资源产生竞争时，必然影响计算任务卸载的决策，使任务卸载的比率随着用户数量的增加而减少。
图中，由于 SPF 调度算法优先选择通信时延最小的链路。
当优势链路占用过多时，剩余链路资源因无法满足其他约束条件，导致计算任务的平均卸载比例大幅下降，也从侧面反映出图~\ref{fig_smallE} 中，SPF 算法下感知设备总能耗急剧上升的原因。
在该图中，从侧面反映出LSW链路调度方法维持较高的计算资源平均卸载比率。
虽然不及最优解给出的调度策略，但基本趋势维持一致。

图~\ref{fig_smallrule} 显示了每个交换机中流表容量的占用情况。
对于最优解（Gurobi）和 SPF 调度算法，不同感知设备总数总数和流表容量占用率并没有直接关系。
在 LSW 调度算法中，有意保持每条链路使用率的平衡性。
因此，随着感知设备的增加，SDN 路由器中的流表占用增长趋势相对稳定。
所以，在SDN网络资源开销增加时，仍然留有高质量的链路预留给新加入的感知设备使用。
在SPF调度算法中，可以观察到 SDN 交换机的流表使用率存在着波动性变化。
但是对于优质链路的完全占用，会在新加入感知设备时产生较多的链路调度变化，导致额外的时间开销。
% 这意味着为了满足更多的用户，链路调度的次数会有很大的变化。这也表明SDN网络中的交换机可能会频繁地改变其状态，这将导致额外的能耗成本。



\subsection{性能测试}

为了比较LSW算法和SPF算法，本节设计了一个拥有100个 SDN 交换机的网络拓扑。
该网络中有30个交换机作为接入点为感知设备提供网络服务。
同时，有40个 SDN 交换机分别连接40个主基站。
其中，感知设备的数量从200到3000依次增加。
这个网络中每个交换机的规则空间是2000。
在该SDN网络设置中，有30\%的链路的数据传输延时不能满足群智感知对感知数据传输的延时要求，由此来模拟真实网络中的不稳定因素。

图~\ref{fig_largeE} 显示了LSW调度算法和 SPF 调度算法对感知设备总能耗的影响。
通过LSW算法，总能耗和用户数量之间的关系几乎是线性的，并没有出现大幅的增长趋势。
当网络中包含3000个感知设备时，SPF算法得到的结果比LSW算法多出了31.9\%。

\begin{figure}[!h]
  \centering
  \includegraphics[width=290pt]{./figures/Sec_ISPA/large_E}
  % \vspace{-1em}
  \vspace{-0.5em}
  \caption{ LSW 和 SPF 调度算法对能量总开销的影响}
  \label{fig_largeE}
  \vspace{-1em}
\end{figure}

图~\ref{fig_largeAu} 显示了LSW调度算法和 SPF 调度算法对平均任务卸载比率的影响。
当用户从800增加到1500时，两种调度算法的平均任务卸载比率都出现大幅下滑。
根据实验过程日志分析，是由于实验网络中人为设置了延时过高的链路，导致任务卸载决策时为避开这些链路而减小了计算任务的卸载比例。
在该测试中，两种调度算法都没有很好的避开高延时链路带来的影响。
但是，相较于 SPF 调度算法，LSW算法的抗干扰能力要更好一些。

\begin{figure}[!h]
  \centering
  \includegraphics[width=290pt]{./figures/Sec_ISPA/large_Au}
  % \vspace{-1em}
  \vspace{-0.5em}
  \caption{LSW 和 SPF 调度算法对平均任务卸载效率的影响}
  \vspace{-1em}
  \label{fig_largeAu}
\end{figure}

图~\ref{fig_largeL} 显示了LSW调度算法和 SPF 调度算法对边缘网络中链接使用数量的影响。当参与群智感知的感知设备数量相同时，LSW方法中使用的链路数比SPF算法中的链路数少10\%。
这也意味着LSW调度算法对 SDN 路由器的流表容量占用更小，可以支撑的感知设备数量更多。

\begin{figure}[!h]
  \centering
  \includegraphics[width=290pt]{./figures/Sec_ISPA/large_link}
  % \vspace{-1em}
  \vspace{-0.5em}
  \caption{LSW 和 SPF 调度算法对网络链路数量的影响}
  \vspace{-1em}
  \label{fig_largeL}
\end{figure}

\section{本章小结}

本章在 SDN 管理的边缘网络，针对群智感知中感知数据计算任务卸载决策，围绕网络资源限制和感知设备的能耗，建立了量化分析模型。
为了深入理解网络资源限制和感知设备的能耗之间的关系，将该模型表述为 ILP 模型，以减少感知设备执行感知数据计算任务的总能耗。
通过对 ILP 模型的分析，本章设计了一种计算任务卸载和网络资源协同调度算法（LSW 调度算法）。
该算法根据每个链路的权重和计算任务在感知设备与主基站上的执行速度，避免了 ILP 模型求解的高计算复杂度，实现了接近最优解的计算任务卸载决策以及通信链路的调度。
通过对比试验，证明了算法的有效性。
在和 SPF 算法的对比实验中，显示出 LSW 调度算法的显著优势。

% 建立了一个SDN网络公式模型，以了解SDN中总能量成本和限制之间的关系。为了最小化总能耗，将这个问题表述为线性规划问题。在对模型进行研究之后，提出了一种链路调度算法，根据每个链路的权重来选择最合适的链路。权重由交换机中规则空间的使用和链路中带宽的使用组成。通过大量实验，证明了算法的有效性。通过对比实验，该算法比SPF算法显示出显著的优势，极大地提高了最优解的性能。


