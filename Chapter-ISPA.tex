\chapter{基于感知数据计算卸载的边缘网络调度机制}

在移动群智感知中，由于移动设备的处理能力存在个体差异，计算能力较弱的移动设备可以将部分感知数据处理任务卸载至边缘服务器上，以减少因本地数据处理导致的时延。
当使用软件定义网络（SDN）管理网络资源时，SDN 交换机的流表容量因三进制内容可寻址存储器（Ternary content addressable memory，简称 TCAM）的容量而受到不可避免的限制。
面对无处不在的移动设备，SDN 在调度移动设备的网络链接时，必须考虑流表容量、带宽和任务卸载决策之间的约束。
基于这些约束条件，本章 首先构建了整形线性规划（Integer Linear Programming，简称 ILP）模型来理解负载决策、传输延迟和以及感知数据处理成本之间的关系。
然后提出二阶段决策算法，根据 SDN 交换机中的流表容量和链路带宽来调度移动设备和边缘服务器的通信链路，并保障任务卸载所带来的能耗收益。
最后通过对比评估，验证了算法的可行性和性能。
并在 SDN 交换机流表不溢出的情况下，达到最佳调度方案90\%的节能效益。

\section{研究背景}

由于移动设备个体性能的差异，同一计算任务在不同移动设备上的运行时间和能耗开销也存在较大的区别。
对于性能较弱的移动设备而言，为了加快部分应用的执行速率，可以使用计算任务卸载技术，将本地难以高效执行的计算过程，迁移到计算能力充沛的云端服务器上，从而提高应用执行效率。
例如，使用移动设备执行导航应用，用户只需要上报自己的地理位置、目的地以及出行方式，云端服务器会根据用户的需求进行路线规划，再将路线结果和地图资源反馈给用户。
借助云端的算力，用户还可以在移动设备上进行复杂的图像处理工作（Adobe Creative Cloud），甚至在平板电脑上游玩画质优良的主机游戏、电脑游戏（云游戏）。

对于移动群智感知而言，大部分研究工作将重心放在参与者激励~\cite{CNKI:JiaChaopeng, DBLP:journals/comsur/ZhangYSLTXM16, CNKI:WuMCSIncentive}和任务分发工作上~\cite{DBLP:conf/huc/LiuGWWYZ16, DBLP:conf/infocom/Xiao0HWL15, DBLP:conf/mass/LiLW15}，这些工作已经取得了良好的效果。
因此，本章的研究重点围绕感知数据的收集工作展开。
在群智感知数据收集过程中，需要移动设备对感知数据进行一定的处理工作再进行上传。
对于普通的数值读取式传感器，这类传感数据体积小、处理逻辑简单，大部分的移动设备可以快速完成原始感知数据的处理工作。
然而，对于视频、音频、图像、雷达信号等类别的传感数据，由于原始感知数据信息量大、且处理算法复杂度高，如果没有专用芯片的帮助，移动设备无法对这类原始感知数据进行实时处理。
为了解决这类原始感知数据的处理工作，在移动群智感知场景中常依靠计算卸载技术借助外部算力对这些感知数据进行处理~\cite{Lee:2013fj, Linthicum:2017vv, Kumar:2013dq}。

% 而用户之间的文件共享，也可以依托云存储服务，无需消耗本地设备的网络资源和存储资源。
% 合理利用任务卸载技术，可以帮助性能较弱的终端设备完成复杂任务，降低执行成本。

% 在移动群智感知应用的执行过程中，计算任务卸载技术也被广泛应用。
在城市感知中，多使用网络摄像头等设备采集大量的视频、图像、音频数据。
在车联网环境中，智能车上的雷达设备也会生成大量的异构传感信息。
对于这些感知设备，其计算能力并不能满足对原始数据的实时处理需求，也没有足够的存储资源保存原始原始数据。
因此，对于这一类群智感知应用，可以将复杂的感知数据处理任务托付给负责收集感知数据的边缘服务节点，在对感知数据处理的同时，也完成了感知数据的收集工作。
因此，在部分实时性要求高、感知数据处理复杂的群智感知应用中，可以借助边缘计算在数据产生源附近部署相应的边缘服务，来实现原始感知数据的实时处理与收集。

然而，边缘计算不同于云计算模型，由于边缘服务器的分布较为独立，没有专用的内部网络支撑计算任务在不同服务器之间的调度。
因此，在进行计算任务卸载时，感知设备和边缘服务器之间的网络链接需要根据计算卸载决策进行协同调度。
基于这一目的，本章利用 SDN 对边缘网络中的网络资源进行管理，利用其控制平面和数据平面的隔离的特征~\cite{Committee:2012un}，实现计算任务卸载和网络资源的协同调度。

% 网络中的设备数量和流量类型正在急剧增长。为了更有效地管理网络，新出现的网络架构SDN被发明出来。SDN的目标是分离控制平面和数据平面~\cite{Committee:2012un}。SDN采用可编程网络，并利用虚拟化技术，这与其他网络体系结构不同。同时，SDN还可以共享网络基础设施，使网络功能实现软件化。

\begin{figure}[!h]
  \centering
  \includegraphics[width=440pt]{./figures/Sec_ISPA/OffloadingSDN.pdf}
  \vspace{-1em}
  \caption{基于 SDN 的计算任务卸载和网络资源协同调度}
  \vspace{-1em}
  \label{fig_OffloadingSDN}
\end{figure}

图~\ref{fig_OffloadingSDN} 展示了移动群智感知中，计算任务卸载和边缘网络资源的协同调度场景。
在该图中，性能不同的感知设备所需要卸载的计算任务比例也不相同，而基站也有计算能力强弱之分。
例如麦克风、照相机这些纯感知设备本身并没有数据处理能力，因此需要将数据处理工作卸载至服务器上。
而音频的处理工作相较于图像处理工作要更为轻松，因此麦克风的原始感知数据可以上传至性能较弱的基站上，而原始图像数据则上传至处理能力较强的基站上。
对于可穿戴设备、全栈式摄像头、手机平板、VR 设备而言，其自身已具备一定的处理能力，因此只需要卸载部分的计算任务。
而对于笔记本电脑等计算能力充沛的设备，所有的数据处理可以在本地执行完之后再上传至基站。
在该场景中，可以通过 SDN 技术对网络连接进行规划，以确保感知数据的传输时延以及链路带宽资源的合理利用。

尽管利用 SDN 可以在边缘网络中实现基于计算任务卸载的网络资源调度，但是在面对成千上万的感知设备时，SDN 能够管理的网络资源会因流表容量受到一定的约束。
在 SDN 交换机中，多路径路由规则通常使用 TCAM 芯片进行存储，而 TCAM 芯片的容量，则代表 SDN 交换机可以存放在流表~\cite{Dasgupta:2012:DMD:2400771.2401550}中的多路径转发规则的数量。
但是由于 TCAM 芯片成本过高，所以 SDN 交换机中的流表通常只能保存10000到15000条转发规则。
所以，在调度计算任务卸载的过程中，不仅要考虑感知设备与边缘服务器的链路带宽、时延是否满足需求，还需要考虑 SDN 交换机能否支撑海量感知设备场景下的多路径转发规则存储。

另一方面，不同边缘服务器的计算能力和使用成本也存在着差异。
因此在使用计算任务卸载时，每个感知设备需要选择合适的边缘服务器进行计算任务卸载，来减少边缘服务器的使用成本。
基于上述约束条件，在移动群智感知应用中，网络资源的调度必须考虑计算任务卸载决策对链路的带宽、时延的需求，以及SDN 交换机的流表容量的约束。
为此，本章提出一种新的链路调度算法对群智感知应用中的计算任务卸载和边缘网络资源进行协同调度，
以实现网络资源的负载均衡，保障计算任务卸载的服务质量，并最大限度地降低感知数据处理能耗成本。
本章的主要贡献如下：

1）建立 ILP 模型来描述计算任务卸载决策、网络资源调度、和感知数据处理能耗之间的关系。

2）为避免 ILP 模型求解的高计算复杂性，提出了二阶段网络资源调度算法，并通过模拟实验验证了该算法的有效性。

\section{问题描述}

\begin{figure}[!b]
  % \vspace{-1em}
  \centering
  \includegraphics[width=400pt]{./figures/Sec_ISPA/scenario.pdf}
  \vspace{-1em}
  \caption{基于感知数据计算任务卸载的边缘计算场景}
  \label{fig_scenario}
\end{figure}

为了对真实场景进行抽象描述，本节以图~\ref{fig_scenario} 为范例对本章的研究问题进行描述。
在现实场景中，通常以子基站围绕主基站的方式部署无线通信网络。
在主基站中，为了辅助通信业务和应用，会增加额外的计算资源和存储资源。
因此，主基站可以作为边缘网络中的边缘服务器，作为感知设备计算任务卸载的目的地。
为了提高无线网络的覆盖率，主基站利用子基站或者无线网络接入点（Wireless Access Point，简称 AP）将网络资源覆盖到更广阔的地理空间中。
通过这种部署，感知设备可以直接利用子基站传输数据，也可以通过子基站再经由主基站完成数据的传输工作。
然而受到地理分布的影响，不同基站之间的链接也有时延和带宽的差异。
因此，感知设备在进行计算任务卸载的同时，不仅需要考虑主基站的性能负载，还需要考虑网络资源中带宽和时延的影响。

根据图~\ref{fig_scenario} 所描述的场景，建立分析模型时需要考虑的对象分为三类：
1）感知设备，2）由 SDN 进行路径管理的子基站，3）可执行感知数据计算任务的主基站。
为了让模型专注于研究计算任务调度和网络资环的协同调度关系，本章在场景建立时做出以下假设: 

（1）感知数据处理任务可以在感知设备或主基站上独立运行；

（2）基站之间的通信链路是稳定的；

（3）所有网络连接均通过 SDN 管理。


% 如图~\ref{fig_scenario} 所示，每个用户通过固定AP访问网络资源。用户和主基站之间的所有链接都由SDN分配。SDN的主要职责是为所有用户安排链路，以提高他们的QoS。同时，SDN的工作对用户是透明的。为了满足更多用户，可以租用云计算资源，如虚拟专用服务器（VPS）、Docker等。你想要的资源越多，你就需要付出越多。

在该场景中，使用$u$来代表单一的感知设备，使用$\boldsymbol{U}$代表所有感知设备构成的集合（ $ u \in \boldsymbol{U} $）。
在边缘网络中，可以执行计算任务的主基站用$s$表示，$\boldsymbol{S}$ 代表这类基站的集合（ $ s \in \boldsymbol{S} $）。
对于负责数据转发的子基站或 AP，统称为 SDN 交换机，使用$r$表示，并用$\boldsymbol{R}$ 代表这类基站的集合（ $ r \in \boldsymbol{R} $）。
考虑到 SDN 通过保存多路径转发规则管理链路，这里使用 $l$ 表示感知设备到主基站的一条链路，$ \boldsymbol{L}$ 代表所有感知设备与所有主基站能够建立的全部链接集合（$l \in \boldsymbol{L} $）。
由于一个感知设备到一个主基站可能存在多条路径，可以利用$l$是否经过$r$来区分起始点和终点相同的路径（章节~\ref{ISPA:Model} 中有详细描述）。

当使用计算任务卸载时，感知设备可以在本地处理部分原始感知数据后再上传至主基站，也可以使用计算任务卸载将原始感知数据交付给主基站处理，待收到处理后的数据在完成数据上传工作。
这两种方法所对应的感知数据处理时延并不相同。
如图~\ref{fig_timestaps}，感知设备 $u$ 在本地对 $1/4$ 的原始感知数据进行计算处理，
然后经由SDN 交换机 $r_1$ 上传 $1/4$ 的原始感知数据至主基站 $s$ 进行处理，余下的原始感知数据则通过SDN 交换机 $r_2$ 和 $r_3$ 交付给主基站 $s'$ 完计算处理工作。
对于本地处理的感知数据部分，将其计算时延定义为 $T_{u\_local}$。
对于交付给主基站 $s$ 处理的感知数据而言，令其网络上传时延为 $T_{us}$，将主基站 $s$ 处理这些原始感知数据的计算时延定义为 $T_{us\_server}$，而返回结果的网络传输时延定义为 $T_{su}$。
因此，感知设备 $u$ 借助主基站 $s$ 处理感知数据的时延为 $T_{us}$、$T_{us\_server}$ 和 $T_{su}$ 三者之和。
同理，感知设备 $u$ 借助主基站 $s'$ 处理感知数据的时延应当为 $T_{us'}$、$T_{us'\_server}$ 和 $T_{s'u}$ 三者之和。
令 $\Tusresponse$ 表示感知设备 $u$ 借助任意主基站 $s$ （$s \in \boldsymbol{S}$）处理感知数据的总时延，则 $\Tusresponse$ 可以利用式~\ref{formula_cloudtime} 来计算。

\begin{figure}[!t]
  \centering
  % \vspace{-1em}
  \includegraphics[width=400pt]{./figures/Sec_ISPA/Delay.pdf}
  \vspace{-0.5em}
  \caption{计算任务卸载场景下感知数据的处理时延}
  % \vspace{-1em}
  \label{fig_timestaps}
\end{figure}

\vspace{-1em}
\begin{equation}
  \label{formula_cloudtime}
  % \begin{aligned}
    \Tusresponse = T_{us} + T_{us\_server} + T_{su},\ \forall \ u \in \boldsymbol{U}, s \in \boldsymbol{S}
  % \end{aligned}
\end{equation}

基于假设条件（1）：计算任务可以在本地设备或边缘服务器上独立运行，感知设备 $u$、任意主基站 $s$ 可以并行处理感知数据。
对于感知设备 $u$ 而言，其感知数据处理时延应该为 $T_{u\_local}$、$T_{us\_server}$ （$s \in \boldsymbol{S}$）中的最大值。
其中，$T_{u\_local}$ 仅和感知设备的处理速度以及感知数据计算任务量有关，而对于 $T_{us\_server}$ ，不仅与被选择的通信链路相关，还与计算任务卸载比例以及主基站的计算能力相关。
除此之外，当计算卸载到不同的主基站时，由于链路的更换使得数据传输时延也随之发生变化。
因此，在该场景中，感知设备的计算卸载比率、计算卸载目标节点的决策都会影响感知数据的实际处理时间。

另一方面，移动群智感知应用中通常会招募海量的感知设备，由于计算卸载的使用，会导致网络中的链接数量成倍增加。
当链路规划不理想时，部分支撑链路的核心SDN 交换机可能因为 SDN 交换机流表容量的限制而无法承载新的链路请求，进而导致网络资源的负载不平衡甚至网络拥塞。
因此，在该场景下，还应当对链路的选择做出适当的调度，以避免流表容量的限制。

% 由于计算任务卸载需要将感知设备将数据交付给主基站，并等待主基站完成任务给予反馈，因此计算任务卸载的发起到完成确认，需要一定的时间开销。
% 在图~\ref{fig_timestaps} 中，${T}_{us}$是从感知设备$u$到主基站$s$的时延。
% $\Tsu$代表从主基站$s$到感知设备$u$的时延。
% $\Tuscloud$是感知设备$u$的计算任务在主基站$s$中的执行时间。
% $\Tusresponse$是感知设备$u$将计算任务卸载到主基站$s$的总时间开销。
% 基于之间的假设条件（2），基站之间的通信链路都处于稳定状态。
% 因此，在感知设备和主基站之间的通信链路不改变的情况下，感知设备和主基站之间的通信时延$\Tus$和$\Tsu$可视为常数。
% 仅当 SDN 网络在资源调度时改变了感知设备和主基站之间的通信链路，$\Tus$和$\Tsu$才会跟随新的链路发生改变。
% 在此模型中，主基站的计算响应时间$\Tusresponse$可以通过时延的总和来计算，如式~\eqref{formula_responsetime} 所示。

% \vspace{-1.5em}
% \begin{equation}
%   \label{formula_responsetime}
%   \Tusresponse = \Tus + \Tsu + \Tuscloud,\ \forall \ u \in \boldsymbol{U}, s \in \boldsymbol{S}
% \end{equation}


\section{基于感知数据计算卸载的边缘网络调度模型与算法}

为了更好地使用数学语言描述面向任务卸载的边缘网络调度问题，本节使用了表~\ref{table_notations_ispa} 中定义的数学符号，其细节含义将在后文中解释。

\begin{table}[!h]
  \caption{数学符号及定义}
  \vspace{-1em}
  \label{table_notations_ispa}
  \centering
  \begin{tabular}{|c|p{8cm}|}
    \hline
    \textbf{数学符号} & \textbf{定义}\\
    \hline
    $\boldsymbol{U}$ & 由感知设备 $u$ 构成的集合\\\hline
    $\boldsymbol{S}$ & 由主基站 $s$ 构成的集合\\\hline
    $\boldsymbol{R}$ & 由 SDN 交换机 $r$ 构成的集合\\\hline
    $\Lus$ & 感知设备$u$ 到主基站 $s$ 的链路 $\lus$ 构成的集合\\\hline
    $\xu$ & 感知设备$u$是否使用计算任务卸载\\\hline
    $\xus$ & 感知设备$u$的计算任务是否卸载到主基站$s$\\\hline
    $\aus$ & 感知设备$u$的计算任务卸载到主基站$s$的比例\\\hline
    $\xlus$ & $\lus$ 是否作为感知设备$u$ 到主基站 $s$ 的上行链路\\\hline
    $\ylus$ & $\lus$ 是否作为感知设备$u$ 到主基站 $s$ 的下行链路\\\hline
    $\Tlus$ & 链路$\lus$的传输时延\\\hline
    $\Blus$ & 链路 $\lus$的带宽资源\\\hline
    $\xrl$ & 链路 $\lus$ 是否经过SDN 交换机 $r$\\\hline
    $\Bu$ & 感知设备 $u$的上行链路带宽需求\\\hline
    $\Bd$ & 感知设备 $u$的下行链路带宽需求\\\hline
    $\eu$ & 感知设备 $u$ 执行计算任务的能耗开销\\\hline
    $\es$ & 主基站 $s$ 执行计算任务的能耗开销\\\hline
    $\lambdau$ & 感知设备$u$上的计算任务到达率\\\hline
    $\mu_u$ & 感知设备$u$的计算任务处理速度\\\hline
    $\mu_s$ & 主基站$s$的计算任务处理速度\\\hline
    % $\Tus$ & \\\hline
    % $\Tsu$ & \\\hline
    $T_{QoS}$ & 群智感知应用中计算任务远端执行时延阈值 \\\hline
  \end{tabular}
\end{table}

\subsection{边缘网络资源调度模型}
\label{ISPA:Model}

基于假设条件（1），感知数据的计算任务可以在感知设备或主基站上独立执行。
因此，可以使用二进制变量来表示感知设备是否利用主基站来实施计算任务。
对于感知设备 $u$，用 $\xus$ 表示其是否将感知数据计算任务卸载至主基站 $s$。
当$\xus = 1$ 时，感知设备 $u$ 使用主基站 $s$ 处理感知数据；当 $\xus = 0$ 时，感知设备 $u$ 不使用主基站 $s$ 。
另一方面，由于感知设备可以划分任意比例的计算任务至主基站上，因此使用 $\aus$（$\aus \in [0,1]$）来代表感知数据计算任务的卸载比例。
当 $\aus = 1$ 时，感知设备$u$的计算任务全部在主基站 $s$ 上执行，当 $\aus = 0$ 时，感知设备 $u$ 不利用主基站 $s$ 处理感知数据。

基于上述定义， $\aus$ 和 $\xus$ 之间的关系可以用式~\eqref{formula_xus}来表达。
该式中，如果 $\aus = 0$，说明感知设备 $u$ 没有将感知数据的计算任务卸载到主基站 $s$，因此 $\xus$ 的值也应该为0。
如果 $\aus \in (0, 1]$，说明感知设备 $u$ 将比例为 $\aus$ 的感知数据计算任务卸载到主基站 $s$，此时 $\xus = 1$，。

\begin{equation}
  \label{formula_xus}
  \begin{gathered}
  \frac{\aus}{A} \leq \xus \leq A \cdot \aus \quad (A \to \infty) \\
  \quad \forall \ u \in \boldsymbol{U}, s \in \boldsymbol{S}, \ 0\leq \aus \leq 1
  \end{gathered}
\end{equation}

对于感知设备 $u$ 而言，令 $\xu$ 表示其是否使用计算卸载。
由于感知设备可以选择多个主基站进行计算任务的卸载，因此只要有任意 $\aus > 0 （s \in \boldsymbol{S}）$，则 $\xu = 1$。
为了方便使用 ILP 模型解模方法求解，这里使用式~\eqref{formula_xu} 定义 $\xu$ 的计算方式。

% \vspace{-0.5em}
\begin{equation}
\label{formula_xu}
\begin{gathered}
\frac{1 - \sum\limits_{s \in \boldsymbol{S}}{\aus}}{A} \leq \xu \leq A \cdot (1 - \sum_{s \in \boldsymbol{S}}{\aus}) \quad (A \to \infty) \\
\forall\ u \in \boldsymbol{U}, s \in \boldsymbol{S}, \ 0\leq \sum_{s \in \boldsymbol{S}}{\aus} \leq 1
\end{gathered}
\end{equation}

针对计算时延的计算，这里使用 $\mu$ 表示不同设备的计算能力。
其中，令$\mu_s$表示主基站 $s$ 的计算能力，令$\mu_u$表示感知设备$u$的本地计算能力。
然后令用 $\lambdau$ 表示感知设备 $u$ 上采集感知数据的速率。
根据排队论原理~\cite{Queueing:systems}，可以借助 $M/M/1$ 模型，计算感知设备 $u$ 在本地执行计算任务的平均时延$T_{u\_local}$。
由于感知设备 $u$ 到主基站 $s$ 的计算任务卸载比率为 $\aus$，因此本地剩余可执行的计算任务比率为 $1 - \sum_{s \in \boldsymbol{S}}\aus$。
则 $T_{u\_local}$ 的最终计算方法如式~\eqref{formula_Tulacal}。

% \vspace{-0.5em}
\begin{equation}
  \label{formula_Tulacal}
  \Tulocal = \frac{\xu}{\uu - (1 - \sum\limits_{s \in \boldsymbol{S}} \aus) \cdot \lambdau}, \quad \forall \ u \in \boldsymbol{U}
\end{equation}

对于主基站 $s$ 而言，需要处理在不同感知设备的计算卸载任务。
因此，主基站 $s$ 上的任务到达率可以用 $\sum_{u \in \boldsymbol{U}} \aus \lambdau$ 表示。
使用 $M/M/1$ 排队论模型，主基站 $s$ 中执行计算任务的平均时延 $T_{s\_server}$ 可以利用式~\eqref{formula_Tscloud} 计算。
% 和在主基站中执行计算任务的平均时间$T_{s\_server}$，可以借助 $M/M/1$ 模型计算得出。

\begin{equation}
\label{formula_Tscloud}
\Tscloud = \frac{\xus}{\us - \sum\limits_{u \in \boldsymbol{U}} \aus \cdot \lambdau}, \quad \forall \ s \in \boldsymbol{S}
\end{equation}

由于 $\Tscloud$ 是主基站 $s$ 处理计算任务的平均时延，在整体分析时，可以用 $\Tscloud$ 代替式~\eqref{formula_cloudtime} 中的 $T_{us\_server}$。
因此，借助式~\ref{formula_cloudtime} 、式~\ref{formula_Tulacal} 和式~\ref{formula_Tscloud} 可以求解感知设备 $u$ 的感知数据处理时延 $\Tusresponse$。
但是在 $\Tusresponse$ 的计算中，还涉及到链路的传输延时。
基于之前的假设条件（2），基站之间的通信链路都处于稳定状态。
这意味着在感知设备和主基站之间的通信链路不改变的情况下，每条链路的传输延时可视为定值。
因此只要能够确定感知设备 $u$ 和主基站 $s$ 之间的具体通信链路，就能够得知 $\Tsu$ 和 $\Tus$ 的值。

为了精准表示复杂网络中的任一连接感知设备 $u$ 和主基站 $s$ 的具体通信路径，这里使用该路径是否经过指定SDN 交换机的方法进行描述。
令网络中的连接 $\lus$ 表示连接感知设备 $u$ 和主基站 $s$ 的一条链路，$\boldsymbol{R}$ 表示 SDN 交换机构成的集合。
通过二进制变量$\xrl$表示链路$\lus$是否通过 SDN 交换机 $r$，其定义如式~\ref{formula_xrl} 。
对于任一指定的感知设备 $u$ 和主基站 $s$，可以利用 $\xrl$ 找出唯一的路径，从而获得 $\Tsu$ 和 $\Tus$ 的值，最终计算出感知设备 $u$ 将感知数据计算任务卸载至主基站 $s$ 的总时延。

\begin{equation}
  \label{formula_xrl}
  \begin{gathered}
  \begin{aligned}
  \xrl = \left\{\begin{aligned}
  & 0,\quad  \lus \text{ 不经过 SDN 交换机 }\, r\\
  & 1,\quad  \lus \text{ 经过 SDN 交换机 }\, r\\
  \end{aligned}
  \right.
  \end{aligned}
  \quad \forall \ u \in \boldsymbol{U}, s \in \boldsymbol{S}, \lus \in \Lus\\
  \end{gathered}
\end{equation}

通过分析感知设备的本地感知数据处理时延和计算卸载处理时延，可以帮助单一感知设备选择合适的主基站进行计算任务卸载。
但是对于海量的群智感知设备而言，感知设备的卸载决策会影响链路的带宽、主基站的资源利用率、 SDN 交换机中的流表使用率以及感知设备和主基站上的能耗开销。
因此，基于种种可利用资源的限制，在该模型中提出了相关约束条件。

\subsection{约束条件}
\label{Constraints}

由于感知设备$u$和主基站$s$通信所使用的上行链路和下行链路可能不同，
为了在模型中精确表述感知设备$u$和主基站$s$之间使用的通信链路，
这里使用二进制变量$\xlus$和$\ylus$来表示是否使用链路$\lus$作为感知设备$u$到主基站$s$的上行链路或下行链路。
由于感知设备$u$和主基站$s$通信与否与计算卸载决策$\xus$有关，所以当 $\xus = 0$ 时，感知设备$u$和主基站$s$之间不存在通信链路。
因此，$\xlus$、$\ylus$ 和 $\xus$的关系首先应当满足式~\eqref{formula_xusl}。

\begin{equation}
  \label{formula_xusl}
  \left\{
    \begin{aligned}
    0 \leq \xlus \leq \xus\\
    0 \leq \ylus \leq \xus
    \end{aligned}
  \right.
  \quad \forall \ \lus \in \Lus, u\in \boldsymbol{U}, s\in \boldsymbol{S}\\
\end{equation}

另一方面，当$\xus = 1$时，感知设备$u$和主基站$s$之间一定存在通信链路，并且对于上行链路和下行链路的数量，分别有且仅有一条。因此，$\xlus$、$\ylus$ 和 $\xus$的关系还应当满足式~\eqref{formula_xusl1}。

\begin{equation}
  \label{formula_xusl1}
  \left\{
    \begin{aligned}
    &\sum_{\lus \in \Lus}\xlus = 1\\
    &\sum_{\lus \in \Lus}\ylus = 1
    \end{aligned}
  \right.
  \quad \forall \ u\in \boldsymbol{U}, s\in \boldsymbol{S}
\end{equation}

待链路选定后，可以利用$\Tlus$来表示链路$\lus$的延迟。借助$\xlus$和$\ylus$，可以通过式~\eqref{formula_Tus} 计算感知设备$u$和主基站$s$之间上行链路时延$\Tus$和下行链路时延$\Tsu$的数值。

\begin{equation}
  \label{formula_Tus}
  \left\{
    \begin{aligned}
    &\Tus = \xlus \cdot \Tlus\\
    &\Tsu = \ylus \cdot \Tlus
    \end{aligned}
  \right.
  \quad \forall \ \lus \in \Lus, u\in \boldsymbol{U}, s\in \boldsymbol{S}
\end{equation}

\textbf{计算卸载服务质量约束:}
当感知设备发起计算卸载请求时，该过程可以理解为感知设备根据任务卸载比例将感知数据发送至主基站，主基站在计算完成后返回处理结果。
对于感知设备而言，使用计算卸载的目的就是加速感知数据的处理以调高群智感知的效率。
由于群质感知的生命周期有限，计算任务在调度决策的时候，要尽可能减少计算任务在主基站上的执行时间。
所以计算任务的平均执行时间成为计算任务调度决策的重要参考指标。
借助章节~\ref{ISPA:Model} 的模型定义，可以利用式~\eqref{formula_Tusresponse} 精确获得感知设备$u$的计算任务在主基站$s$上的平均执行时间 $\Tusresponse$。

% 尽管任务可以在本地或云中执行，但是用户总是希望他们能够尽快得到反馈，对于任务在哪里执行，用户并不关心。所以，任务在调度时应尽可能让用户的等待时间减少。因此，平均服务时间是一个非常重要的服务质量指标。通过以上工作，可以利用式~\eqref{formula_Tusresponse} 精确地计算平均服务时间。

\begin{equation}
\label{formula_Tusresponse}
\begin{gathered}
\Tusresponse = \xlus \Tlus + \frac{\xus}{\us-\sum\limits_{u \in \boldsymbol{U}}\aus \cdot \lambdau} + \ylus \Tlus,
\quad \forall \ \lus \in \Lus, u\in \boldsymbol{U}, s\in \boldsymbol{S}
\end{gathered}
\end{equation}

由于主基站之间可能存在性能差异，在此将计算任务被分配给执行时间最短的主基站。
因此，感知设备$u$的感知数据计算任务平均执行时间必须满足式~\eqref{formula_tscloudconstr} 所示的限制条件。
式中，$T_{QoS}$为群智感知应用中感知数据处理时延阈值。

\begin{equation}
\label{formula_tscloudconstr}
  \left\{
    \begin{aligned}
    % \frac{\xu}{\uu - (1 - \sum\limits_{s \in \boldsymbol{S}} \aus) \cdot \lambdau} \leq T_{QoS},\\
    &\xlus \Tlus + \frac{\xus}{\us-\sum\limits_{u \in \boldsymbol{U}}\aus \cdot \lambdau} + \ylus \Tlus \leq T_{QoS}\\
    &\us-\sum\limits_{u \in \boldsymbol{U}}\aus \cdot \lambdau > 0
    \end{aligned}
  \right.
  \quad \forall \lus \  \in \Lus, u\in \boldsymbol{U}, s \in \boldsymbol{S}
\end{equation}

同样，感知设备在本地处理感知数据的时延也应当不超过群智感知应用中感知数据处理时延阈值，如式~\eqref{formula_tulocalconstr} 所示。

\begin{equation}
\label{formula_tulocalconstr}
  \left\{
    \begin{aligned}
    &\frac{\xu}{\uu - (1 - \sum\limits_{s \in \boldsymbol{S}} \aus) \cdot \lambdau} \leq T_{QoS}\\
    &\uu - (1 - \sum\limits_{s \in \boldsymbol{S}}\aus) \cdot \lambdau > 0
    % \xlus \Tl + \frac{\xus}{\us-\sum\limits_{u \in \boldsymbol{U}}\aus \cdot \lambdau} + \ylus \Tl\\
    \end{aligned}
  \right.
  \quad \forall \ u\in \boldsymbol{U}, s\in \boldsymbol{S}
\end{equation}

\textbf{带宽资源约束:}
与传统网络一样，SDN中的每条链路都有自己的最大带宽限制。
假设感知设备$u$通过链路$\lus$与主基站$s$连接。
由于感知设备数据众多，中间链路存在严重的复用现象。
因此，链路$\lus$的带宽必须满足所有感知设备的通信需求。
假设链路$\lus$的最大带宽是$\Blus$，并且上行链路和下行链路的带宽需求分别为$\Bu$和$\Bd$。那么约束条件可以描述为式~\eqref{formula_Bandwidth}。

\begin{equation}
\label{formula_Bandwidth}
\begin{gathered}
\sum\limits_{u \in \boldsymbol{U}} \sum\limits_{s\in \boldsymbol{S}}\lambdau\aus(\xlus \cdot \Bu + \ylus \cdot \Bd) \leq \Blus, \ 
\forall \ \lus\in \Lus, u\in \boldsymbol{U}, s\in \boldsymbol{S}\\
\end{gathered}
\end{equation}

\textbf{流表容量限制:}
除了带宽限制之外，SDN中的交换机的流表容量也存在上限，即每台 SDN 交换机所能支撑的链路数量存在极限。
在此，令 $C_r$ 表示 SDN 交换机$r$的流表容量。
对于任意一条链路 $\lus$ 而言，只要其经过 SDN 交换机$r$，则交换机$r$使用一条转发规则来记录链路 $\lus$。
因此，对于任意 SDN 交换机，承载的规则数目不可超过其流表容量$C_r$。
利用之前定义的二进制变量 $xlus$ ，二者的关系应当满足如式~\eqref{formula_linkconstr}。

\begin{equation}
\label{formula_linkconstr}
\begin{gathered}
\sum\limits_{u \in \boldsymbol{U}}\sum\limits_{s \in \boldsymbol{S}}\sum\limits_{\lus \in Lus}(\xlus + \ylus) \cdot \xrl \leq C_r,
\quad  \forall\ u \in \boldsymbol{U}, s \in \boldsymbol{S}, \lus \in \Lus, r\in R\\
\end{gathered}
\end{equation}

\subsection{优化目标}

通过上一小节建立的模型，可以获得感知设备 $u$ 所执行的感知数据计算任务量为 $\lambdau(1-\sum_{s\in \boldsymbol{S}}\aus)$，而主基站 $s$ 上所执行的感知数据计算任务量为 $\sum_{u\in \boldsymbol{U}}\aus\lambdau$。
令感知设备 $u$ 本地执行计算任务的能耗成本为$\eu$，主基站 $s$ 中执行计算任务的能耗成本定义为$\es$。
则感知数据的处理总能耗 $E$ 可以利用式~\ref{formula_Energy} 来计算。
而本章的最终优化目标，就是在上述约束条件下，令 $E$ 取最小值。

\begin{equation}
\label{formula_Energy}
  \begin{gathered}
    E = \sum\limits_{u\in \boldsymbol{U}}(\lambdau(1-\sum\limits_{s\in \boldsymbol{S}}\aus)\eu + \lambdau\sum\limits_{s\in \boldsymbol{S}}\aus\es),
    \quad \forall\ u \in \boldsymbol{U}, s \in \boldsymbol{S}
  \end{gathered}
\end{equation}

但是，约束条件中的式~\eqref{formula_tscloudconstr} 和式~\eqref{formula_tulocalconstr} 并不能构成线性规划问题，因此需要作出适当的转化。
针对式~\eqref{formula_tscloudconstr}，定义新的变量 $\beta_{us}$ 和 $\delta_{us}$。
其计算方法如式~\eqref{formula_beta} 和式~\eqref{formula_delta} 。

\begin{equation}
  \label{formula_beta}
  \begin{gathered}
    \beta_{us} = \aus \xlus,
    \quad \forall\ u \in \boldsymbol{U}, s \in \boldsymbol{S}
  \end{gathered}
\end{equation}

\begin{equation}
  \label{formula_delta}
  \begin{gathered}
    \delta_{us} = \aus \ylus,
    \quad \forall\ u \in \boldsymbol{U}, s \in \boldsymbol{S}
  \end{gathered}
\end{equation}

由于$\aus$ 和 $\xlus$、$\ylus$ 之间存在线性关系，所以对于变量 $\beta_{us}$ 和 $\delta_{us}$，也存在如式~\eqref{formula_beta_linear} 和式~\eqref{formula_delta_linear} 所示的线性关系。

\begin{equation}
  \label{formula_beta_linear}
  \left\{
  \begin{aligned}
    &0 \leq \beta_{us} \leq \aus \\
    &\aus + \xlus -1 \leq \beta_{us} \leq \xlus
  \end{aligned}
  \right.
  \quad \forall\ u \in \boldsymbol{U}, s \in \boldsymbol{S}
\end{equation}

\begin{equation}
  \label{formula_delta_linear}
  \left\{
  \begin{aligned}
    &0 \leq \delta_{us} \leq \aus \\
    &\aus + \ylus -1 \leq \delta_{us} \leq \ylus
  \end{aligned}
  \right.
  \quad \forall\ u \in \boldsymbol{U}, s \in \boldsymbol{S}
\end{equation}

将式~\eqref{formula_beta_linear} 和式~\eqref{formula_delta_linear} 代入式~\eqref{formula_tscloudconstr} 中，可以得到如式~\eqref{formula_cloudtime_linear} 的所示线性约束条件。

\begin{equation}
  \label{formula_cloudtime_linear}
  \begin{gathered}
    \mu_s (\xlus \Tlus + \ylus \Tlus - T_{QoS}) + \sum_{u \in \boldsymbol{U}}\lambdau(T_{QoS} - \beta_{us} - \delta_{us}) + \xus \leq 0,\\
    \quad \forall\ u \in \boldsymbol{U}, s \in \boldsymbol{S}
  \end{gathered}
\end{equation}

针对式~\eqref{formula_tulocalconstr}，由于该式中 $\uu - (1 - \sum_{s \in \boldsymbol{S}}\aus) \cdot \lambdau$ 大于0。
因此该式可以在消除分母后转化为式~\eqref{formula_tulocalconstr_linear}。

\begin{equation}
  \label{formula_tulocalconstr_linear}
  \begin{gathered}
    \xu - \uu T_{QoS} + (1 - \sum_{s \in \boldsymbol{S}}\aus) T_{QoS} \leq 0 ,
    \quad \forall\ u \in \boldsymbol{U}, s \in \boldsymbol{S}
  \end{gathered}
\end{equation}

整理上述讨论中的所有约束条件，可以将感知设备的能耗成本转化为含整型线性规划模型求解问题，其描述如式~\eqref{formula_energy} 所示。

\begin{equation}
\label{formula_energy}
\begin{aligned}
\text{求最小值\:}&{:}\ E\\
\text{限制条件\:}&{:}\ 式~\eqref{formula_xusl}，式~\eqref{formula_xusl1}，式~\eqref{formula_Bandwidth},\\
&\ \ 式~\eqref{formula_linkconstr}，式~\eqref{formula_cloudtime_linear}，式~\eqref{formula_tulocalconstr_linear}
\end{aligned}
\end{equation}

\subsection{二阶段网络资源调度算法}

针对本章提出的 ILP 模型，可以利用数学工具计算出计算任务卸载与网络资源协同调度的最佳决策。
但是 ILP 模型求解的高计算复杂度，让最佳决策的求解时间成本难以接受。
同时，随着网络规模的不断扩大，求解时间也成指数级趋势上升。
为此，本节设计了一种二阶段启发式算法，来避免 ILP 模型求解的繁冗过程，实现快速获取次优协同调度决策的目的。

该算法主要负责两个阶段的工作。首先，该算法确定$\sum_{s \in \boldsymbol{S}}\aus$和$\sum_{u \in \boldsymbol{U}}\aus$，创建针对感知设备$u$和主基站$s$的不同组合，每种组合创建首选链接集合。
然后，该算法为针对模型中的约束条件，为感知设备$u$和服务器$s$分配最合适的链路，并调整$\aus$，减少感知设备的能源开销。

\textbf{第一阶段 （算法~\ref{algo_aus}）}:
在式~\eqref{formula_Energy}，$\lambdau$、$\es$ 和 $\eu$ 是常数。
变量 $\aus$ 是确定感知设备总能耗 $E$ 值的唯一变量。
为了降低总能耗开销，必须在 $\es$ 和 $\eu$ 之间调整系数$\aus$。
因此，当 $\es > \eu$ 时，$\aus$ 应当使 $\sum_{s \in \boldsymbol{S}}{\aus}$ 取最大值，当 $\es \leq \eu$ 时，$\aus$ 应当使 $\sum_{s \in \boldsymbol{S}}{\aus}$ 取最小值。
因此，该算法第一阶段的工作是找出$\sum_{s \in \boldsymbol{S}}\aus$的取值范围。

利用约束条件~\eqref{formula_tscloudconstr} 和~\eqref{formula_tulocalconstr}，可以得到$\sum_{s \in \boldsymbol{S}}\aus$的范围和$\sum_{u \in \boldsymbol{U}}\aus$的范围：

\vspace{-1em}

\begin{equation*}
\begin{gathered}
\sum_{s \in \boldsymbol{S}}\aus \in [max(0, 1- \frac{\uu}{\lambdau}), 1], \quad \forall\ u \in \boldsymbol{U}, s \in \boldsymbol{S}\\
\sum_{u \in \boldsymbol{U}}\aus \in [0, \frac{\us}{\lambdau}], \quad \forall\ u \in \boldsymbol{U}, s \in \boldsymbol{S}
% \vspace{-1em}
\end{gathered}
\end{equation*}

在确定$\sum_{s \in \boldsymbol{S}}\aus$和$\sum_{u \in \boldsymbol{U}}\aus$的范围后，可以根据约束条件式~\eqref{formula_tulocalconstr} 找出一组从感知设备$u$到主基站$s$的链接集合。
这些信息能够作为算法~\ref{algo_findminpaths} 的输入，帮助感知设备$u$选择连接主基站$s$的最佳链路。

\begin{algorithm}[!h]
\setstretch{\algostretch}
\KwIn{$\lambdau$ : 感知设备$u$的计算任务到达速率}
\KwIn{$\uu$ : 感知设备$u$的计算任务处理速度}
\KwIn{$\us$: 主基站$s$的计算任务处理速度}
\KwIn{$\eu$: 感知设备执行计算任务的能耗成本}
\KwIn{$\es$ : 主基站执行计算任务的能耗成本}
\KwData{网络结构、每条链路的带宽、时延数据}
% \KwData{$Occ[1:T]$: 每个程序当前的NCP大小，初始为0，随着缓存路的分配增加，最终为每个程序在整个缓存上的NCP}
\If {$\eu \leq \es$}{
  \For{$u \in \boldsymbol{U}$}{
    $\sum_{s \in \boldsymbol{S}}\aus = max(0, 1 - \frac{\uu}{\lambdau})$
  }
}\Else{
  \For{$s \in \boldsymbol{S}$}{
    $\sum_{u \in \boldsymbol{U}}\aus = min(1, \frac{\us}{\lambdau})$
  }
}
\For{$u \in \boldsymbol{U}$}{
  \For{$s \in \boldsymbol{S}$}{
    为感知设备$u$ 和主基站 $s$ 创建可用链路集合$\Lus$\\
    对链路集合$\Lus$ 中的 链路按时延升序排序
  }
}
$\as = \sum_{s \in \boldsymbol{S}}\aus, \  \au = \sum_{u \in \boldsymbol{U}}\aus$\\
\KwOut{$\aus, \au, \Lus$}
\caption{创建感知设备$u$ 和主基站 $s$ 的可选链路集，并根据计算任务的平均执行时延约束决定卸载比例 $\aus$}
\label{algo_aus}
\end{algorithm}

\textbf{第二阶段 （算法~\ref{algo_findminpaths}）}:
在算法~\ref{algo_aus}中，可以得到$\sum_{s \in \boldsymbol{S}}\aus$的最优解。
在此阶段中，本算法负责找出所有$\aus$，使得感知设备$u$ 对不同主基站$s$的卸载比例总和逼近最佳值。
同时，由于流表容量、带宽以及延迟的限制，利用贪心算法和动态规划算法相结合来达到目标。

\begin{algorithm}[!h]
% \vspace{-0.5em}
\setstretch{\algostretch}
\KwIn{$\as$ : 算法~\ref{algo_aus} 的输出}
\KwIn{$\au$ : 算法~\ref{algo_aus} 的输出}
\KwIn{$\Lus$: 算法~\ref{algo_aus} 的输出}
\KwIn{$T_{QoS}$: 群智感知应用对感知数据处理时延要求的阈值}
\KwData{ SDN 交换机集合$R$以及每个路由器$r$的流表容量 $C_r$}
% \KwData{$Occ[1:T]$: 每个程序当前的NCP大小，初始为0，随着缓存路的分配增加，最终为每个程序在整个缓存上的NCP}
将所有 SDN 交换机的带宽使用率和流表使用率以及$\aus$置 $0$\\
% 将所有 $\aus$ 置 $0$\\
将$\boldsymbol{U}$ 中的元素以 $\lambdau$ 为基准按升序排序\\
将$\boldsymbol{S}$ 中的元素以 $\us$ 为基准按升序排序\\
\For{$u \in \boldsymbol{U}$}{
  \If {$T_{u\_local} < T_{Qos}$}{
    $\aus = 0\  (s \in \boldsymbol{S})$ 若本地执行计算任务效率符合要求，则不进行计算卸载
  }
  \Else{
    \For {$s \in \boldsymbol{S}$}{
      \If {$1 \leq \frac{\lambdau}{\us}$ \textbf{and} $T_{s\_cloud} < T_{QoS}$}{
        若$s$ 的处理$u$的所有数据时延满足要求，则开始选择链路\\
        \For {$l \in \Lus$}{
          从算法~\ref{algo_aus} 得到的集合 $\Lus$ 中遍历链路\\
          \If{若 $l$ 被选中后，所有链路的流表占用率和带宽占用率最大差值不超过$10\%$}{
            $\aus = 1$， \ $u$ 将所有感知数据交给$s$ 处理\\
            $\xlus[u,s,l] = \ylus[u,s,l] =  1$， \ 选定上下行链路\\
            \textbf{next} $u$
          }
        }
      }
      \If {$T_{s\_cloud} < T_{QoS}$ \textbf{and} $\au < 1$}{
        若$s$ 的处理$u$的部分数据时延满足要求，则开始选择链路\\
        \For {$l \in \Lus$}{
          % 从算法~\ref{algo_aus} 得到的集合 $\Lus$ 中遍历链路\\
          \If{若 $l$ 被选中后，所有链路的流表占用率和带宽占用率最大差值不超过$10\%$}{
            $\aus = \frac{\lambdau}{\us}$，\ 确定计算任务卸载的比例\\
            $\xlus[u,s,l] = \ylus[u,s,l] = 1$ ，\ 选定上下行链路\\
          }
        }
      }
    }
  }
}
\KwOut{计算卸载比例 $\aus$ ；链路选择决策 $\xlus$ 和 $\ylus$}
\caption{根据计算卸载决策为感知设备 $u$ 在约束条件下选择合适的链路}
\label{algo_findminpaths}
% \vspace{-0.5em}
\end{algorithm}

首先，按$\lambdau$的升序对感知设备进行排序，再按$\us$升序对主基站进行排序。
这里的策略是优先从计算任务到达速度较慢的感知设备上卸载任务。
一般来说，主基站的能耗成本和其计算性能是正相关的。
因此，主基站的最佳选择策略是在满足平均计算时延的前提条件下，优先使用能耗最小的主基站。
然后，根据第一阶段得出的链接结合$\Lus$，遵循贪心算法来选择感知设备$u$和主基站$s$之间最快的链接。 
由于带宽资源也存在约束条件，所以最快的链路不一定是最佳选择。
因此，再利用动态规划的思量来平衡边缘网络中各链路的带宽占用。
在这一步中，使用流表容量的使用率和链路带宽占用率作为链路选择的权值。

为了保障链路资源的负载均衡，需要避免高质量链路被提前消耗完的窘境。
一旦高质量的链路被占用完全，受影响的感知设备必须降低计算任务卸载比率，这将导致感知设备的能耗成本增加。
因此算法中规定所有链路的两种占用率中，最大值和最小值相差不得超过10\%。
当某个链路的权值比其他链接的权值高出 10\%时，该链接会从可选择链接中屏蔽。
这种设定可以使各链路的带宽负载以及 SDN 交换机中流表的使用率均匀增加，实现链路调度的负载均衡。



% 链路调度算法旨在使带宽使用率和链路使用率同时增长。 在规则空间和带宽限制下保障用户的QoS而不产生额外开销是链路选择的重要依据。 因此，本文的链路调度策略为每个链路设定权重，并且使链路的权重尽可能相近。 所以，两种资源的占用率的权重比例相同。 其中，所有链路的最大权重差值不能超过10\%。 当某个链接的权重比其他链接的权重高出 10\%时，该链接会从可选择链接中屏蔽。 这个策略是为了防止高 QoS 链接被快速占满。 一旦高质量的链路和服务器被占用完全，其余用户必须降低卸载比率以确保QoS，这将导致能耗成本的增加。

\section{实验结果与分析}

为了评估依据权重的链路调度（Link Scheduling with Weight，简称LSW）算法的性能，本节将 LSW 调度算法和最短路径优先（Shortest Path First，简称 SPF）算法以及利用 Gurobi~\footnote{https://www.gurobi.com} 求得的最优解调度进行比较。
在实验中，使用了两种不同的网络拓扑结构。
第一种是小型网络拓扑，用于验证 LSW 调度算法的可行性。
第二个网络拓扑是一个有拥有100个SDN交换机的模拟网络，用来对比传统的SPF调度算法和LSW调度算法。

\subsection{算法准确性测试}

第一个小型网络的拓扑结构如图~\ref{fig_smallNetwork} 所示。在此图中，定义了每条链路的延迟和带宽。SDN交换机的流表容量依次定义为100，100，80，80，80，100，100。
在该网络中，交换机$0$和交换机$1$是接入点，交换机$5$和交换机$6$连接到不同的主基站。
连接到交换机$6$的主基站比连接到交换机$5$的主基站快10\%。
分布在交换机$0$和交换机$1$之间的感知设备数量从10开始，以10为步进增加至100，且每个感知设备的任务到达率设置为25个任务/秒至50个任务/秒，且均匀分布。
其中，感知设备执行计算任务的能耗成本 $\eu=10$，主基站执行计算任务的能耗成本$\es=100$。

\begin{figure}[!t]
  \centering
  \begin{subfigure}[b]{0.45\linewidth}
    \includegraphics[width=180pt]{./figures/Sec_ISPA/NetworkX_spring_L}
    \label{fig_smallNetworkL}
    \caption{链路时延（秒）}
  \end{subfigure} %
  \begin{subfigure}[b]{0.45\linewidth}    
    \includegraphics[width=180pt]{./figures/Sec_ISPA/NetworkX_spring_B}
    \label{fig_smallNetworkB}
    \caption{链路带宽（兆比特/秒）}
  \end{subfigure} 
  \caption{用于准确性测试的小型网络拓扑}
  \label{fig_smallNetwork}
\end{figure}

利用三种不同的调度方法，首先比较感知设备总能耗的开销。
结果如图~\ref{fig_smallE} 所示，当感知设备数量较少时，由于各类资源占用没有达到阈值，所以链路调度算法不会对感知设备的总能耗产生太大的影响。
随着感知设备数量的增加，其能源成本之间的差距急剧扩大。
当网络中有100个感知设备时，最坏情况下，LSW调度算法产生的感知设备总能耗比最优解（Gurobi计算得出）高12.6 \%；最好情况下，LSW调度算法比SPF调度算法节约26.4\%的感知设备总能耗。
另外，当感知设备达到100时，由于SDN 交换机中的流表容量已经趋于满载，此时可以发现 LSW 调度算法在这种情况情况下存在一定的局限性，导致感知设备总能耗急剧上升。
整体而言，LSW 调度算法所能达到的效果和最优解基本持平，总能耗差异在15\%以内。

\begin{figure}[!h]
  \centering
  \includegraphics[width=290pt]{./figures/Sec_ISPA/small_E}
  \vspace{-1em}
  \caption{不同调度方法对感知设备总能耗的影响}
  % \vspace{-0.5em}
  \label{fig_smallE}
\end{figure}

% 链路调度算法LSW的目标是最小化总能耗$E$。因此，比较了三种方法计算出的不同的$E$值。如图~\ref{fig_smallE} 所示，不同的链路调度策略会影响卸载场景中的总能耗。当用户数量较少时，链路调度算法不会对能耗产生太大影响。随着用户数量的增加，能源成本之间的差距急剧扩大。当网络中有100个用户时，LSW方法的总能耗比最优解（Gurobi计算得出）高12.6 \%，比SPF方法的最优解高36.4\%。同时，100名用户使SDN网络基本上处于满负荷状态。因此，当SDN网络的负载接近满负荷时，LSW方法此时存在局限性。从这个图中，当SDN网络负载不满时，LSW方法和最优解之间的差异可以减少到小于10\%。

图~\ref{fig_smallAu} 描述的是同一网络拓扑下，不同调度方法对感知设备平均计算任务卸载比率的影响。
图中，感知设备数量从20到50区间，由于感知设备任务到达率以及计算任务处理速度设置的差异，产生了计算任务平均卸载比率上扬的趋势。
但就整体而言，随着感知设备的增加，需要使用的网络资源逐渐增多，当网络资源产生竞争时，必然影响计算任务卸载的决策，使任务卸载的比率随着用户数量的增加而减少。
图中，由于 SPF 调度算法优先选择通信时延最小的链路。
当优势链路占用过多时，剩余链路资源因无法满足其他约束条件，导致计算任务的平均卸载比例大幅下降，也从侧面反映出图~\ref{fig_smallE} 中，SPF 算法下感知设备总能耗急剧上升的原因。
在该图中，从侧面反映出LSW链路调度方法维持较高的计算资源平均卸载比率。
虽然不及最优解给出的调度策略，但基本趋势维持一致。

\vspace{-0.5em}
\begin{figure}[!h]
  \centering
  \includegraphics[width=290pt]{./figures/Sec_ISPA/small_Au}
  \vspace{-0.5em}
  \caption{不同调度方法对平均计算任务卸载比率的影响}
  \vspace{-0.5em}
  \label{fig_smallAu}
\end{figure}
\vspace{-0.5em}

图~\ref{fig_smallrule} 显示了每个交换机中流表容量的占用情况。
对于最优解（Gurobi）和 SPF 调度算法，不同感知设备总数总数和流表容量占用率并没有直接关系。
在 LSW 调度算法中，有意保持每条链路使用率的平衡性。
因此，随着感知设备的增加，SDN 交换机中的流表占用增长趋势相对稳定。
所以，在SDN网络资源开销增加时，仍然留有高质量的链路预留给新加入的感知设备使用。
在SPF调度算法中，可以观察到 SDN 交换机的流表使用率存在着波动性变化。
但是对于优质链路的完全占用，会在新加入感知设备时产生较多的链路调度变化，导致额外的时间开销。
% 这意味着为了满足更多的用户，链路调度的次数会有很大的变化。这也表明SDN网络中的交换机可能会频繁地改变其状态，这将导致额外的能耗成本。

\begin{figure}[!h]
  \centering
  \begin{subfigure}[h]{0.99\linewidth}
    \centering
    \includegraphics[width=415pt]{./figures/Sec_ISPA/small_rule_grb.pdf}
    \label{fig_smallNetworkRG}
    \vspace{-0.5em}
    \caption{使用 Gurobi 最优解时流表使用率}
  \end{subfigure}
  % \vspace{1em}
  \begin{subfigure}[h]{0.99\linewidth}
    \centering
    \includegraphics[width=415pt]{./figures/Sec_ISPA/small_rule_lsw.pdf}
    \label{fig_smallNetworkRL}
    \vspace{-0.5em}
    \caption{LSW 调度算法下的流表使用率}
  \end{subfigure}
  \begin{subfigure}[h]{0.99\linewidth}
    \centering
    \includegraphics[width=415pt]{./figures/Sec_ISPA/small_rule_spf.pdf}
    \label{fig_smallNetworkRS}
    \vspace{-0.5em}
    \caption{SPF 调度算法下的流表使用率}
  \end{subfigure}
  \vspace{-0.5em}
  \caption{不同调度算法对流表使用率的影响}
% \vspace{-1.2em}
\label{fig_smallrule}
\end{figure}
% \vspace{-1em}




\subsection{性能测试}

为了比较LSW算法和SPF算法，本节设计了一个拥有100个 SDN 交换机的网络拓扑。
该网络中有30个交换机作为接入点为感知设备提供网络服务。
同时，有40个 SDN 交换机分别连接40个主基站。
其中，感知设备的数量从200到3000依次增加。
这个网络中每个交换机的规则空间是2000。
在该SDN网络设置中，有30\%的链路的数据传输时延不能满足群智感知对感知数据传输的时延要求，由此来模拟真实网络中的不稳定因素。

图~\ref{fig_largeE} 显示了LSW调度算法和 SPF 调度算法对感知设备总能耗的影响。
通过LSW算法，总能耗和用户数量之间的关系几乎是线性的，并没有出现大幅的增长趋势。
当网络中包含3000个感知设备时，SPF算法得到的结果比LSW算法多出了31.9\%。

\begin{figure}[!h]
  \centering
  \includegraphics[width=290pt]{./figures/Sec_ISPA/large_E}
  % \vspace{-1em}
  \vspace{-0.5em}
  \caption{ LSW 和 SPF 调度算法对能量总开销的影响}
  \label{fig_largeE}
  \vspace{-1em}
\end{figure}

图~\ref{fig_largeAu} 显示了LSW调度算法和 SPF 调度算法对平均任务卸载比率的影响。
当用户从800增加到1500时，两种调度算法的平均任务卸载比率都出现大幅下滑。
根据实验过程日志分析，是由于实验网络中人为设置了时延过高的链路，导致任务卸载决策时为避开这些链路而减小了计算任务的卸载比例。
在该测试中，两种调度算法都没有很好的避开高时延链路带来的影响。
但是，相较于 SPF 调度算法，LSW算法的抗干扰能力要更好一些。

\begin{figure}[!h]
  \centering
  \includegraphics[width=290pt]{./figures/Sec_ISPA/large_Au}
  % \vspace{-1em}
  \vspace{-0.5em}
  \caption{LSW 和 SPF 调度算法对平均任务卸载效率的影响}
  \vspace{-1em}
  \label{fig_largeAu}
\end{figure}

图~\ref{fig_largeL} 显示了LSW调度算法和 SPF 调度算法对边缘网络中链接使用数量的影响。当参与群智感知的感知设备数量相同时，LSW方法中使用的链路数比SPF算法中的链路数少10\%。
这也意味着LSW调度算法对 SDN 交换机的流表容量占用更小，可以支撑的感知设备数量更多。

\begin{figure}[!h]
  \centering
  \includegraphics[width=290pt]{./figures/Sec_ISPA/large_link}
  % \vspace{-1em}
  \vspace{-0.5em}
  \caption{LSW 和 SPF 调度算法对网络链路数量的影响}
  \vspace{-1em}
  \label{fig_largeL}
\end{figure}

\section{本章小结}

本章在 SDN 管理的边缘网络，针对群智感知中感知数据计算任务卸载决策，围绕网络资源限制和感知设备的能耗，建立了量化分析模型。
为了深入理解网络资源限制和感知设备的能耗之间的关系，将该模型表述为 ILP 模型，以减少感知设备执行感知数据计算任务的总能耗。
通过对 ILP 模型的分析，本章设计了一种计算任务卸载和网络资源协同调度算法（LSW 调度算法）。
该算法根据每个链路的权重和计算任务在感知设备与主基站上的执行速度，避免了 ILP 模型求解的高计算复杂度，实现了接近最优解的计算任务卸载决策以及通信链路的调度。
通过对比试验，证明了算法的有效性。
在和 SPF 算法的对比实验中，显示出 LSW 调度算法的显著优势。

% 建立了一个SDN网络公式模型，以了解SDN中总能量成本和限制之间的关系。为了最小化总能耗，将这个问题表述为线性规划问题。在对模型进行研究之后，提出了一种链路调度算法，根据每个链路的权重来选择最合适的链路。权重由交换机中规则空间的使用和链路中带宽的使用组成。通过大量实验，证明了算法的有效性。通过对比实验，该算法比SPF算法显示出显著的优势，极大地提高了最优解的性能。


